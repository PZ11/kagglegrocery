{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-12-14 20:59:31,111 __main__ 29 [INFO][<module>] start \n",
      "2017-12-14 20:59:31,111 __main__ 29 [INFO][<module>] start \n",
      "2017-12-14 20:59:31,111 __main__ 29 [INFO][<module>] start \n",
      "2017-12-14 20:59:31,111 __main__ 29 [INFO][<module>] start \n",
      "2017-12-14 20:59:31,111 __main__ 29 [INFO][<module>] start \n",
      "2017-12-14 20:59:31,111 __main__ 29 [INFO][<module>] start \n",
      "2017-12-14 20:59:31,117 __main__ 84 [INFO][<module>] start \n",
      "2017-12-14 20:59:31,117 __main__ 84 [INFO][<module>] start \n",
      "2017-12-14 20:59:31,117 __main__ 84 [INFO][<module>] start \n",
      "2017-12-14 20:59:31,117 __main__ 84 [INFO][<module>] start \n",
      "2017-12-14 20:59:31,117 __main__ 84 [INFO][<module>] start \n",
      "2017-12-14 20:59:31,117 __main__ 84 [INFO][<module>] start \n",
      "2017-12-14 20:59:31,163 __main__ 96 [INFO][<module>] load data successful \n",
      "2017-12-14 20:59:31,163 __main__ 96 [INFO][<module>] load data successful \n",
      "2017-12-14 20:59:31,163 __main__ 96 [INFO][<module>] load data successful \n",
      "2017-12-14 20:59:31,163 __main__ 96 [INFO][<module>] load data successful \n",
      "2017-12-14 20:59:31,163 __main__ 96 [INFO][<module>] load data successful \n",
      "2017-12-14 20:59:31,163 __main__ 96 [INFO][<module>] load data successful \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data prepared\n",
      "training data processed\n",
      "Train a XGBoost model\n",
      "[0]\ttrain-rmse:0.882769\teval-rmse:0.901916\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.\n",
      "[1]\ttrain-rmse:0.680822\teval-rmse:0.712611\n",
      "[2]\ttrain-rmse:0.541072\teval-rmse:0.595472\n",
      "[3]\ttrain-rmse:0.446071\teval-rmse:0.532819\n",
      "[4]\ttrain-rmse:0.378527\teval-rmse:0.498857\n",
      "[5]\ttrain-rmse:0.327716\teval-rmse:0.476809\n",
      "[6]\ttrain-rmse:0.294286\teval-rmse:0.469092\n",
      "[7]\ttrain-rmse:0.259219\teval-rmse:0.465268\n",
      "[8]\ttrain-rmse:0.241465\teval-rmse:0.462411\n",
      "[9]\ttrain-rmse:0.223026\teval-rmse:0.464082\n",
      "[10]\ttrain-rmse:0.201466\teval-rmse:0.463689\n",
      "[11]\ttrain-rmse:0.185354\teval-rmse:0.464576\n",
      "[12]\ttrain-rmse:0.171306\teval-rmse:0.467755\n",
      "[13]\ttrain-rmse:0.154396\teval-rmse:0.469857\n",
      "[14]\ttrain-rmse:0.139579\teval-rmse:0.472306\n",
      "[15]\ttrain-rmse:0.127222\teval-rmse:0.474059\n",
      "[16]\ttrain-rmse:0.12134\teval-rmse:0.474642\n",
      "[17]\ttrain-rmse:0.115151\teval-rmse:0.475344\n",
      "[18]\ttrain-rmse:0.106245\teval-rmse:0.47711\n",
      "[19]\ttrain-rmse:0.098843\teval-rmse:0.479693\n",
      "[20]\ttrain-rmse:0.096685\teval-rmse:0.480491\n",
      "[21]\ttrain-rmse:0.089591\teval-rmse:0.481489\n",
      "[22]\ttrain-rmse:0.081819\teval-rmse:0.483259\n",
      "[23]\ttrain-rmse:0.081575\teval-rmse:0.483587\n",
      "[24]\ttrain-rmse:0.075058\teval-rmse:0.484775\n",
      "[25]\ttrain-rmse:0.073813\teval-rmse:0.485344\n",
      "[26]\ttrain-rmse:0.068038\teval-rmse:0.486384\n",
      "[27]\ttrain-rmse:0.062934\teval-rmse:0.487992\n",
      "[28]\ttrain-rmse:0.05948\teval-rmse:0.488596\n",
      "Stopping. Best iteration:\n",
      "[8]\ttrain-rmse:0.241465\teval-rmse:0.462411\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-12-14 20:59:35,009 __main__ 183 [INFO][<module>] end \n",
      "2017-12-14 20:59:35,009 __main__ 183 [INFO][<module>] end \n",
      "2017-12-14 20:59:35,009 __main__ 183 [INFO][<module>] end \n",
      "2017-12-14 20:59:35,009 __main__ 183 [INFO][<module>] end \n",
      "2017-12-14 20:59:35,009 __main__ 183 [INFO][<module>] end \n",
      "2017-12-14 20:59:35,009 __main__ 183 [INFO][<module>] end \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'avg_m06': 1535, 'Day': 1050, 'DOW': 954, 'Month': 126, 'avg_m07': 878, 'WOY': 1130}\n",
      "Eval All, Number of rows in test is 392\n",
      "Eval all, Forecast Period From: 2017-07-26 00:00:00  To:  2017-08-10 00:00:00\n",
      "Eval P1, Number of rows in test is 147\n",
      "Eval P1, Forecast Period From: 2017-07-26 00:00:00  To:  2017-07-31 00:00:00\n",
      "Eval P2, Number of rows in test is 245\n",
      "Eval P2, Forecast Period From: 2017-08-01 00:00:00  To:  2017-08-10 00:00:00\n",
      "Eval All Weighted NWRMSLE =  0.5636382513319332\n",
      "Eval P1  Weighted NWRMSLE =  0.44078890231212076\n",
      "Eval P2  Weighted NWRMSLE =  0.6258785820096059\n",
      "Bias = 0.281783\n",
      "WMAPE = 0.43619\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "from logging import StreamHandler, DEBUG, Formatter, FileHandler, getLogger\n",
    "\n",
    "import sklearn.metrics as skl_metrics\n",
    "import xgboost as xgb\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import math\n",
    "\n",
    "logger = getLogger(__name__)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "DIR = './result_tmp/'\n",
    "\n",
    "log_fmt = Formatter('%(asctime)s %(name)s %(lineno)d [%(levelname)s][%(funcName)s] %(message)s ')\n",
    "handler = StreamHandler()\n",
    "handler.setLevel('INFO')\n",
    "handler.setFormatter(log_fmt)\n",
    "logger.addHandler(handler)\n",
    "\n",
    "handler = FileHandler(DIR + 'train.py.log', 'a')\n",
    "handler.setLevel(DEBUG)\n",
    "handler.setFormatter(log_fmt)\n",
    "logger.setLevel(DEBUG)\n",
    "logger.addHandler(handler)\n",
    "\n",
    "logger.info('start')\n",
    "\n",
    "def create_feature_map(features):\n",
    "    outfile = open('xgb.fmap', 'w')\n",
    "    for i, feat in enumerate(features):\n",
    "        outfile.write('{0}\\t{1}\\tq\\n'.format(i, feat))\n",
    "    outfile.close()\n",
    "\n",
    "def NWRMSLE(y, pred, weights=None):\n",
    "    err2 = skl_metrics.mean_squared_log_error(y, pred, sample_weight=weights)\n",
    "    return math.sqrt(err2)\n",
    "\n",
    "def NWRMSLE_A(y, pred, weights):\n",
    "    y = np.array(y)\n",
    "    pred = np.array(pred)\n",
    "    weights = np.array(weights)\n",
    "    weighted_errors = np.dot(np.square(np.log1p(pred) - np.log1p(y)), np.transpose(weights))\n",
    "    weights_sum = np.sum(weights)\n",
    "    return math.sqrt(weighted_errors/weights_sum)\n",
    "\n",
    "def NWRMSLE_lgb(pred, dtrain):\n",
    "    y = list(dtrain.get_label())\n",
    "    score = NWRMSLE(y, pred)\n",
    "    return 'NWRMSLE', score, False\n",
    "\n",
    "def eval_test(test_e):\n",
    "\n",
    "    test_e['weights'] = 1\n",
    "    test_e.loc[(test_e.perishable == 1), ('weights')] = 1.25\n",
    "\n",
    "    result = NWRMSLE(test_e.unit_sales.astype(np.float64),test_e.pred_sales.astype(np.float64), test_e.weights)\n",
    "\n",
    "    print(\"Eval All, Number of rows in test is\", test_e.shape[0])\n",
    "    print(\"Eval all, Forecast Period From:\", min(test_e.date),\" To: \", max(test_e.date))\n",
    "\n",
    "    #### check result on first 6 days.\n",
    "    test_p1 = test_e.loc[(test_e.date < '2017-08-01'), ]\n",
    "    result_p1 = NWRMSLE_A(test_p1.unit_sales.astype(np.float32),test_p1.pred_sales.astype(np.float32), test_p1.weights)\n",
    "\n",
    "    print(\"Eval P1, Number of rows in test is\", test_p1.shape[0])\n",
    "    print(\"Eval P1, Forecast Period From:\", min(test_p1.date),\" To: \", max(test_p1.date))\n",
    "\n",
    "    #### check result on last 10 days.\n",
    "    test_p2 = test_e.loc[(test_e.date >= '2017-08-01'), ]\n",
    "    result_p2 = NWRMSLE_A(test_p2.unit_sales.astype(np.float32),test_p2.pred_sales.astype(np.float32), test_p2.weights)\n",
    "\n",
    "    print(\"Eval P2, Number of rows in test is\", test_p2.shape[0])\n",
    "    print(\"Eval P2, Forecast Period From:\", min(test_p2.date),\" To: \", max(test_p2.date))\n",
    "\n",
    "    print(\"Eval All Weighted NWRMSLE = \",result)\n",
    "    print(\"Eval P1  Weighted NWRMSLE = \",result_p1)\n",
    "    print(\"Eval P2  Weighted NWRMSLE = \",result_p2)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------\n",
    "\n",
    "logger.info('start')\n",
    "\n",
    "items = pd.read_csv('../../input/items.csv'  )\n",
    "\n",
    "dtypes = {'id':'uint32', 'item_nbr':'int32', 'store_nbr':'int8', 'unit_sales':'float32'}\n",
    "#train_all = pd.read_csv('../input/train.csv', usecols=[1,2,3,4,5], dtype=dtypes, parse_dates=['date'] )\n",
    "train_all = pd.read_csv('../../input/train_small.csv', usecols=[1,2,3,4,5], dtype=dtypes, parse_dates=['date'] )\n",
    "\n",
    "df_train = train_all.loc[((train_all.date >= '2016-06-01') & (train_all.date <= '2016-08-31' ))\n",
    "                         |((train_all.date >= '2017-06-01') & (train_all.date <= '2017-08-31' )) , ]\n",
    "del train_all\n",
    "\n",
    "logger.info('load data successful')\n",
    "\n",
    "#train['unit_sales'] =  train['unit_sales'].apply(pd.np.log1p) #logarithm conversion\n",
    "\n",
    "df_train.loc[(df_train.unit_sales<0),'unit_sales'] = 0 # eliminate negatives\n",
    "df_train.loc[:, 'unit_sales'].fillna(0, inplace=True) # fill NaNs\n",
    "\n",
    "df_train['DOW'] = df_train['date'].dt.dayofweek\n",
    "df_train['WOY'] = df_train['date'].dt.weekofyear\n",
    "df_train['Year'] = df_train['date'].dt.year\n",
    "df_train['Month'] = df_train['date'].dt.month\n",
    "df_train['Day'] = df_train['date'].dt.day\n",
    "\n",
    "print('training data prepared')\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------\n",
    "\n",
    "train_m06 = df_train.loc[(df_train.Month == 6),]\n",
    "    \n",
    "ma_m06 = train_m06[['item_nbr','store_nbr','Year','unit_sales']].groupby(['item_nbr','store_nbr','Year'])/\n",
    "['unit_sales'].mean().to_frame('avg_m06')\n",
    "ma_m06.reset_index(inplace=True)\n",
    "\n",
    "df_train = pd.merge(df_train, ma_m06, how='left', on=['item_nbr','store_nbr','Year'])\n",
    "\n",
    "#features = (['DOW', 'WOY', 'Month', 'Day', 'avg_m06'])\n",
    "#print(features)\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------\n",
    "\n",
    "train_m07 = df_train.loc[(df_train.Month == 7),]\n",
    "    \n",
    "ma_m07 = train_m07[['item_nbr','store_nbr','Year','unit_sales']].groupby(['item_nbr','store_nbr','Year'])['unit_sales'].mean().to_frame('avg_m07')\n",
    "ma_m07.reset_index(inplace=True)\n",
    "df_train = pd.merge(df_train, ma_m07, how='left', on=['item_nbr','store_nbr','Year'])\n",
    "\n",
    "features = (['DOW', 'WOY', 'Month', 'Day', 'avg_m06', 'avg_m07'])\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------\n",
    "train = df_train.loc[(df_train.date >= '2016-07-01') & (df_train.date <= '2016-08-31' ), ]\n",
    "test = df_train.loc[(df_train.date > '2017-07-25') & (df_train.date <= '2017-08-10' ), ]\n",
    "\n",
    "\n",
    "print('training data processed')\n",
    "\n",
    "params = {\"objective\": \"reg:linear\",\n",
    "          \"booster\" : \"gbtree\",\n",
    "          \"eta\": 0.3,\n",
    "          \"max_depth\": 10,\n",
    "          \"subsample\": 0.9,\n",
    "          \"colsample_bytree\": 0.7,\n",
    "          \"silent\": 1,\n",
    "          \"seed\": 1301\n",
    "          }\n",
    "num_boost_round = 300\n",
    "\n",
    "print(\"Train a XGBoost model\")\n",
    "X_train, X_valid = train_test_split(train, test_size=0.5, random_state=10)\n",
    "y_train = np.log1p(X_train.unit_sales)\n",
    "y_valid = np.log1p(X_valid.unit_sales)\n",
    "dtrain = xgb.DMatrix(X_train[features], y_train)\n",
    "dvalid = xgb.DMatrix(X_valid[features], y_valid)\n",
    "\n",
    "watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "model_xgb = xgb.train(params, dtrain, num_boost_round, evals=watchlist, \\\n",
    "  early_stopping_rounds=20, verbose_eval=True)\n",
    "\n",
    "\n",
    "create_feature_map(features)\n",
    "importance = model_xgb.get_fscore(fmap='xgb.fmap')\n",
    "print(importance)\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------------------\n",
    "#Load test\n",
    "#test = valid\n",
    "test['pred_sales'] = np.exp(model_xgb.predict(xgb.DMatrix(test[features])))\n",
    "\n",
    "\n",
    "#---------------------- test_e to evaluate the result --------------------------------\n",
    "#weights = np.ones(test.shape[0])\n",
    "test_e = pd.merge(test, items, on='item_nbr',how='inner')\n",
    "eval_test(test_e)\n",
    "\n",
    "test_e['error'] =  abs(test_e.pred_sales - test_e.unit_sales)\n",
    "print(\"Bias =\",  (test_e.pred_sales.sum() - test_e.unit_sales.sum()) /  test_e.unit_sales.sum())\n",
    "print(\"WMAPE =\",  abs(test_e.error.sum() - test_e.unit_sales.sum()) /  test_e.unit_sales.sum())\n",
    "\n",
    "#-------------------------------------------------------------------------------------\n",
    "logger.info('end')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2017-07-26    23\n",
       "2017-07-27    23\n",
       "2017-07-28    24\n",
       "2017-07-29    25\n",
       "2017-07-30    27\n",
       "2017-07-31    25\n",
       "2017-08-01    26\n",
       "2017-08-02    26\n",
       "2017-08-03    26\n",
       "2017-08-04    24\n",
       "2017-08-05    24\n",
       "2017-08-06    24\n",
       "2017-08-07    23\n",
       "2017-08-08    25\n",
       "2017-08-09    27\n",
       "2017-08-10    20\n",
       "dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.groupby(['date']).size()\n",
    "#df_train.info()\n",
    "#np.random.seed(2013)\n",
    "#df_1 = train.sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>unit_sales</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>DOW</th>\n",
       "      <th>WOY</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>avg_m06</th>\n",
       "      <th>avg_m07</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>2016</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4.724138</td>\n",
       "      <td>5.451613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>10</td>\n",
       "      <td>103501</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>2016</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2.269231</td>\n",
       "      <td>2.740741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>11</td>\n",
       "      <td>103501</td>\n",
       "      <td>7.0</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>2016</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3.517241</td>\n",
       "      <td>4.357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>12</td>\n",
       "      <td>103501</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>2016</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3.192308</td>\n",
       "      <td>3.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>13</td>\n",
       "      <td>103501</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>2016</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2.083333</td>\n",
       "      <td>2.892857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  store_nbr  item_nbr  unit_sales onpromotion  DOW  WOY  Year  \\\n",
       "734 2016-07-01          9    103501         3.0       False    4   26  2016   \n",
       "735 2016-07-01         10    103501         1.0       False    4   26  2016   \n",
       "736 2016-07-01         11    103501         7.0       False    4   26  2016   \n",
       "737 2016-07-01         12    103501         5.0       False    4   26  2016   \n",
       "738 2016-07-01         13    103501         4.0       False    4   26  2016   \n",
       "\n",
       "     Month  Day   avg_m06   avg_m07  \n",
       "734      7    1  4.724138  5.451613  \n",
       "735      7    1  2.269231  2.740741  \n",
       "736      7    1  3.517241  4.357143  \n",
       "737      7    1  3.192308  3.571429  \n",
       "738      7    1  2.083333  2.892857  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
