{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-01-04 14:08:18,155 __main__ 35 [INFO]    [<module>] start \n",
      "2018-01-04 14:08:18,155 __main__ 35 [INFO]    [<module>] start \n",
      "2018-01-04 14:08:18,155 __main__ 35 [INFO]    [<module>] start \n",
      "2018-01-04 14:08:18,155 __main__ 35 [INFO]    [<module>] start \n",
      "2018-01-04 14:08:18,155 __main__ 35 [INFO]    [<module>] start \n",
      "2018-01-04 14:08:18,155 __main__ 35 [INFO]    [<module>] start \n",
      "2018-01-04 14:08:18,155 __main__ 35 [INFO]    [<module>] start \n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import sys\n",
    "import math\n",
    "import gc\n",
    "import sklearn.metrics as skl_metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# import math\n",
    "# import sklearn.metrics as skl_metrics\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from logging import StreamHandler, DEBUG, Formatter, FileHandler, getLogger\n",
    "\n",
    "logger = getLogger(__name__)\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "DIR = '../logs/'\n",
    "\n",
    "log_fmt = Formatter('%(asctime)s %(name)s %(lineno)d [%(levelname)s]\\\n",
    "    [%(funcName)s] %(message)s ')\n",
    "handler = StreamHandler()\n",
    "handler.setLevel('INFO')\n",
    "handler.setFormatter(log_fmt)\n",
    "logger.addHandler(handler)\n",
    "\n",
    "handler = FileHandler(DIR + 'train.py.log', 'a')\n",
    "handler.setLevel(DEBUG)\n",
    "handler.setFormatter(log_fmt)\n",
    "logger.setLevel(DEBUG)\n",
    "logger.addHandler(handler)\n",
    "\n",
    "logger.info('start')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_out = pd.read_pickle('../data/storeitem_train_1s.p')\n",
    "val_out = pd.read_pickle('../data/storeitem_val_1s.p')\n",
    "X_test_out = pd.read_pickle('../data/storeitem_test_1s.p')\n",
    "\n",
    "item_train_out = pd.read_pickle('../data/item_train_1s.p')\n",
    "item_val_out = pd.read_pickle('../data/item_val_1s.p')\n",
    "item_X_test_out = pd.read_pickle('../data/item_test_1s.p')\n",
    "\n",
    "df_test = pd.read_csv(\n",
    "    \"../input/test_1s.csv\", usecols=[0, 1, 2, 3, 4],\n",
    "    dtype={'onpromotion': bool},\n",
    "    parse_dates=[\"date\"]  # , date_parser=parser\n",
    ").set_index(\n",
    "    ['store_nbr', 'item_nbr', 'date']\n",
    ")\n",
    "\n",
    "\n",
    "items = pd.read_csv(\n",
    "    \"../input/items.csv\",\n",
    ").set_index(\"item_nbr\")\n",
    "items = items.reindex(train_out.item_nbr)\n",
    "\n",
    "items_val = pd.read_csv(\n",
    "    \"../input/items.csv\",\n",
    ").set_index(\"item_nbr\")\n",
    "items_val = items_val.reindex(val_out['item_nbr'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_1 = '1s'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "param_1 = '1s'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-01-04 14:08:18,421 __main__ 13 [INFO]    [<module>] Load data successful \n",
      "2018-01-04 14:08:18,421 __main__ 13 [INFO]    [<module>] Load data successful \n",
      "2018-01-04 14:08:18,421 __main__ 13 [INFO]    [<module>] Load data successful \n",
      "2018-01-04 14:08:18,421 __main__ 13 [INFO]    [<module>] Load data successful \n",
      "2018-01-04 14:08:18,421 __main__ 13 [INFO]    [<module>] Load data successful \n",
      "2018-01-04 14:08:18,421 __main__ 13 [INFO]    [<module>] Load data successful \n",
      "2018-01-04 14:08:18,421 __main__ 13 [INFO]    [<module>] Load data successful \n",
      "2018-01-04 14:08:18,496 __main__ 26 [INFO]    [<module>] Preparing traing dataset... \n",
      "2018-01-04 14:08:18,496 __main__ 26 [INFO]    [<module>] Preparing traing dataset... \n",
      "2018-01-04 14:08:18,496 __main__ 26 [INFO]    [<module>] Preparing traing dataset... \n",
      "2018-01-04 14:08:18,496 __main__ 26 [INFO]    [<module>] Preparing traing dataset... \n",
      "2018-01-04 14:08:18,496 __main__ 26 [INFO]    [<module>] Preparing traing dataset... \n",
      "2018-01-04 14:08:18,496 __main__ 26 [INFO]    [<module>] Preparing traing dataset... \n",
      "2018-01-04 14:08:18,496 __main__ 26 [INFO]    [<module>] Preparing traing dataset... \n",
      "2018-01-04 14:08:18,642 __main__ 53 [INFO]    [<module>] Training and predicting models... \n",
      "2018-01-04 14:08:18,642 __main__ 53 [INFO]    [<module>] Training and predicting models... \n",
      "2018-01-04 14:08:18,642 __main__ 53 [INFO]    [<module>] Training and predicting models... \n",
      "2018-01-04 14:08:18,642 __main__ 53 [INFO]    [<module>] Training and predicting models... \n",
      "2018-01-04 14:08:18,642 __main__ 53 [INFO]    [<module>] Training and predicting models... \n",
      "2018-01-04 14:08:18,642 __main__ 53 [INFO]    [<module>] Training and predicting models... \n",
      "2018-01-04 14:08:18,642 __main__ 53 [INFO]    [<module>] Training and predicting models... \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "items = pd.read_csv(\n",
    "    \"../input/items.csv\",\n",
    ").set_index(\"item_nbr\")\n",
    "items = items.reindex(train_out.item_nbr)\n",
    "\n",
    "items_val = pd.read_csv(\n",
    "    \"../input/items.csv\",\n",
    ").set_index(\"item_nbr\")\n",
    "items_val = items_val.reindex(val_out['item_nbr'])\n",
    "\n",
    "logger.info('Load data successful')\n",
    "\n",
    "###############################################################################\n",
    "# Merge item features with item_store features\n",
    "\n",
    "del train_out[\"index\"]\n",
    "del item_train_out[\"index\"]\n",
    "\n",
    "train_out = pd.merge(train_out, item_train_out, how='inner', on=['item_nbr','date'])\n",
    "val_out = pd.merge(val_out, item_val_out, how='inner', on=['item_nbr','date'])\n",
    "X_test_out = pd.merge(X_test_out, item_X_test_out, how='inner', on=['item_nbr','date'])\n",
    "\n",
    "###############################################################################\n",
    "logger.info('Preparing traing dataset...')\n",
    "\n",
    "all_columns = train_out.columns.tolist()\n",
    "\n",
    "y_columns = ['day'+str(i) for i in range(1, 17)]\n",
    "x_columns = [item for item in all_columns if item not in y_columns]\n",
    "\n",
    "features_all = x_columns\n",
    "features_all.remove(\"date\") \n",
    "features_all.remove(\"item_nbr\") \n",
    "features_all.remove(\"store_nbr\") \n",
    "\n",
    "X_train_out = train_out[x_columns]\n",
    "X_val_out = val_out[x_columns]\n",
    "\n",
    "y_train = train_out[y_columns].values\n",
    "y_val = val_out[y_columns].values\n",
    "\n",
    "X_train_allF = X_train_out[features_all]\n",
    "X_val_allF = X_val_out[features_all]\n",
    "X_test_allF = X_test_out[features_all]\n",
    "\n",
    "#del train_out, val_out\n",
    "#del X_train_out, X_val_out, X_test_out\n",
    "gc.collect()\n",
    "\n",
    "##########################################################################\n",
    "logger.info('Training and predicting models...')\n",
    "\n",
    "params = {\n",
    "    'num_leaves': 31,\n",
    "    'objective': 'regression',\n",
    "    'min_data_in_leaf': 300,\n",
    "    'learning_rate': 0.1,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 2,\n",
    "    'metric': 'l2',\n",
    "    'num_threads': 4\n",
    "}\n",
    "\n",
    "MAX_ROUNDS = 500\n",
    "val_pred = []\n",
    "test_pred = []\n",
    "cate_vars = []\n",
    "\n",
    "\n",
    "train_week_2017 = 7\n",
    "if param_1 != \"val\":\n",
    "    train_week_2017 = 9\n",
    "    \n",
    "features_all = X_train_allF.columns.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "train_out[\"date\"] = pd.to_datetime(train_out[\"date\"])\n",
    "if ((param_1 == \"val\") or (param_1 == \"1s\")):\n",
    "    train_out = train_out.loc[train_out[\"date\"] < '2017-07-19', ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-01-04 14:08:18,808 __main__ 4 [INFO]    [<module>] Step 1 \n",
      "2018-01-04 14:08:18,808 __main__ 4 [INFO]    [<module>] Step 1 \n",
      "2018-01-04 14:08:18,808 __main__ 4 [INFO]    [<module>] Step 1 \n",
      "2018-01-04 14:08:18,808 __main__ 4 [INFO]    [<module>] Step 1 \n",
      "2018-01-04 14:08:18,808 __main__ 4 [INFO]    [<module>] Step 1 \n",
      "2018-01-04 14:08:18,808 __main__ 4 [INFO]    [<module>] Step 1 \n",
      "2018-01-04 14:08:18,808 __main__ 4 [INFO]    [<module>] Step 1 \n",
      "/home/zyp/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1030: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "======================================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.249349\tvalid_1's l2: 0.239901\n",
      "[200]\ttraining's l2: 0.230128\tvalid_1's l2: 0.222061\n",
      "[300]\ttraining's l2: 0.214812\tvalid_1's l2: 0.20676\n",
      "[400]\ttraining's l2: 0.201696\tvalid_1's l2: 0.193711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-01-04 14:08:23,011 __main__ 61 [INFO]    [<module>] mean_7_2017: 54966.97\n",
      "mean_14_2017: 53449.86\n",
      "mean_42_2017: 17466.03\n",
      "mean_21_2017: 6195.68\n",
      "promo_0: 4786.38\n",
      "dow_26_0_mean: 4695.80\n",
      "mean_3_2017: 3515.54\n",
      "dow_8_0_mean: 3297.29\n",
      "dow_13_0_mean: 2820.91\n",
      "dow_52_0_mean: 2275.05\n",
      "day_1_2017: 1646.07\n",
      "mean_91_2017: 1390.68\n",
      "dow_4_0_mean: 1258.72\n",
      "mean_30_2017: 1100.88\n",
      "mean_182_2017: 1073.54\n",
      "item_mean_7_2017: 968.49\n",
      "promo_14_2017: 877.60\n",
      "mean_60_2017: 823.54\n",
      "dow_1_0_mean: 740.27\n",
      "item_dow_4_0_mean: 723.10\n",
      "mean_ly_n16d_2017: 723.00\n",
      "item_mean_21_2017: 662.46\n",
      "dow_ly3w_0_mean: 651.98\n",
      "item_day_1_2017: 651.14\n",
      "promo_140_2017: 649.65\n",
      "mean_ly_7_2017: 649.41\n",
      "dow_ly8w_0_mean: 620.89\n",
      "item_dow_52_0_mean: 604.68\n",
      "item_dow_13_0_mean: 594.33\n",
      "mean_140_2017: 587.80\n",
      "item_mean_91_2017: 587.37\n",
      "item_mean_42_2017: 580.70\n",
      "item_mean_364_2017: 569.88\n",
      "mean_ly_30_2017: 563.48\n",
      "item_dow_26_0_mean: 556.83\n",
      "mean_ly_14_2017: 551.38\n",
      "mean_364_2017: 496.60\n",
      "item_mean_182_2017: 482.07\n",
      "l2y_1d_d0: 457.39\n",
      "mean_ly_21_2017: 449.35\n",
      "promo_60_2017: 405.74\n",
      "ly_1d_d0: 403.66\n",
      "promo_7: 206.64\n",
      "promo_14: 99.07\n",
      "promo_9: 73.60\n",
      "promo_2: 69.49\n",
      "promo_15: 60.81\n",
      "promo_5: 28.00\n",
      "promo_10: 24.63\n",
      "promo_3: 23.19\n",
      "promo_8: 16.49\n",
      "promo_4: 14.33\n",
      "promo_11: 13.10\n",
      "promo_6: 11.79\n",
      "promo_12: 9.54\n",
      "promo_13: 6.73\n",
      "promo_1: 6.59 \n",
      "2018-01-04 14:08:23,011 __main__ 61 [INFO]    [<module>] mean_7_2017: 54966.97\n",
      "mean_14_2017: 53449.86\n",
      "mean_42_2017: 17466.03\n",
      "mean_21_2017: 6195.68\n",
      "promo_0: 4786.38\n",
      "dow_26_0_mean: 4695.80\n",
      "mean_3_2017: 3515.54\n",
      "dow_8_0_mean: 3297.29\n",
      "dow_13_0_mean: 2820.91\n",
      "dow_52_0_mean: 2275.05\n",
      "day_1_2017: 1646.07\n",
      "mean_91_2017: 1390.68\n",
      "dow_4_0_mean: 1258.72\n",
      "mean_30_2017: 1100.88\n",
      "mean_182_2017: 1073.54\n",
      "item_mean_7_2017: 968.49\n",
      "promo_14_2017: 877.60\n",
      "mean_60_2017: 823.54\n",
      "dow_1_0_mean: 740.27\n",
      "item_dow_4_0_mean: 723.10\n",
      "mean_ly_n16d_2017: 723.00\n",
      "item_mean_21_2017: 662.46\n",
      "dow_ly3w_0_mean: 651.98\n",
      "item_day_1_2017: 651.14\n",
      "promo_140_2017: 649.65\n",
      "mean_ly_7_2017: 649.41\n",
      "dow_ly8w_0_mean: 620.89\n",
      "item_dow_52_0_mean: 604.68\n",
      "item_dow_13_0_mean: 594.33\n",
      "mean_140_2017: 587.80\n",
      "item_mean_91_2017: 587.37\n",
      "item_mean_42_2017: 580.70\n",
      "item_mean_364_2017: 569.88\n",
      "mean_ly_30_2017: 563.48\n",
      "item_dow_26_0_mean: 556.83\n",
      "mean_ly_14_2017: 551.38\n",
      "mean_364_2017: 496.60\n",
      "item_mean_182_2017: 482.07\n",
      "l2y_1d_d0: 457.39\n",
      "mean_ly_21_2017: 449.35\n",
      "promo_60_2017: 405.74\n",
      "ly_1d_d0: 403.66\n",
      "promo_7: 206.64\n",
      "promo_14: 99.07\n",
      "promo_9: 73.60\n",
      "promo_2: 69.49\n",
      "promo_15: 60.81\n",
      "promo_5: 28.00\n",
      "promo_10: 24.63\n",
      "promo_3: 23.19\n",
      "promo_8: 16.49\n",
      "promo_4: 14.33\n",
      "promo_11: 13.10\n",
      "promo_6: 11.79\n",
      "promo_12: 9.54\n",
      "promo_13: 6.73\n",
      "promo_1: 6.59 \n",
      "2018-01-04 14:08:23,011 __main__ 61 [INFO]    [<module>] mean_7_2017: 54966.97\n",
      "mean_14_2017: 53449.86\n",
      "mean_42_2017: 17466.03\n",
      "mean_21_2017: 6195.68\n",
      "promo_0: 4786.38\n",
      "dow_26_0_mean: 4695.80\n",
      "mean_3_2017: 3515.54\n",
      "dow_8_0_mean: 3297.29\n",
      "dow_13_0_mean: 2820.91\n",
      "dow_52_0_mean: 2275.05\n",
      "day_1_2017: 1646.07\n",
      "mean_91_2017: 1390.68\n",
      "dow_4_0_mean: 1258.72\n",
      "mean_30_2017: 1100.88\n",
      "mean_182_2017: 1073.54\n",
      "item_mean_7_2017: 968.49\n",
      "promo_14_2017: 877.60\n",
      "mean_60_2017: 823.54\n",
      "dow_1_0_mean: 740.27\n",
      "item_dow_4_0_mean: 723.10\n",
      "mean_ly_n16d_2017: 723.00\n",
      "item_mean_21_2017: 662.46\n",
      "dow_ly3w_0_mean: 651.98\n",
      "item_day_1_2017: 651.14\n",
      "promo_140_2017: 649.65\n",
      "mean_ly_7_2017: 649.41\n",
      "dow_ly8w_0_mean: 620.89\n",
      "item_dow_52_0_mean: 604.68\n",
      "item_dow_13_0_mean: 594.33\n",
      "mean_140_2017: 587.80\n",
      "item_mean_91_2017: 587.37\n",
      "item_mean_42_2017: 580.70\n",
      "item_mean_364_2017: 569.88\n",
      "mean_ly_30_2017: 563.48\n",
      "item_dow_26_0_mean: 556.83\n",
      "mean_ly_14_2017: 551.38\n",
      "mean_364_2017: 496.60\n",
      "item_mean_182_2017: 482.07\n",
      "l2y_1d_d0: 457.39\n",
      "mean_ly_21_2017: 449.35\n",
      "promo_60_2017: 405.74\n",
      "ly_1d_d0: 403.66\n",
      "promo_7: 206.64\n",
      "promo_14: 99.07\n",
      "promo_9: 73.60\n",
      "promo_2: 69.49\n",
      "promo_15: 60.81\n",
      "promo_5: 28.00\n",
      "promo_10: 24.63\n",
      "promo_3: 23.19\n",
      "promo_8: 16.49\n",
      "promo_4: 14.33\n",
      "promo_11: 13.10\n",
      "promo_6: 11.79\n",
      "promo_12: 9.54\n",
      "promo_13: 6.73\n",
      "promo_1: 6.59 \n",
      "2018-01-04 14:08:23,011 __main__ 61 [INFO]    [<module>] mean_7_2017: 54966.97\n",
      "mean_14_2017: 53449.86\n",
      "mean_42_2017: 17466.03\n",
      "mean_21_2017: 6195.68\n",
      "promo_0: 4786.38\n",
      "dow_26_0_mean: 4695.80\n",
      "mean_3_2017: 3515.54\n",
      "dow_8_0_mean: 3297.29\n",
      "dow_13_0_mean: 2820.91\n",
      "dow_52_0_mean: 2275.05\n",
      "day_1_2017: 1646.07\n",
      "mean_91_2017: 1390.68\n",
      "dow_4_0_mean: 1258.72\n",
      "mean_30_2017: 1100.88\n",
      "mean_182_2017: 1073.54\n",
      "item_mean_7_2017: 968.49\n",
      "promo_14_2017: 877.60\n",
      "mean_60_2017: 823.54\n",
      "dow_1_0_mean: 740.27\n",
      "item_dow_4_0_mean: 723.10\n",
      "mean_ly_n16d_2017: 723.00\n",
      "item_mean_21_2017: 662.46\n",
      "dow_ly3w_0_mean: 651.98\n",
      "item_day_1_2017: 651.14\n",
      "promo_140_2017: 649.65\n",
      "mean_ly_7_2017: 649.41\n",
      "dow_ly8w_0_mean: 620.89\n",
      "item_dow_52_0_mean: 604.68\n",
      "item_dow_13_0_mean: 594.33\n",
      "mean_140_2017: 587.80\n",
      "item_mean_91_2017: 587.37\n",
      "item_mean_42_2017: 580.70\n",
      "item_mean_364_2017: 569.88\n",
      "mean_ly_30_2017: 563.48\n",
      "item_dow_26_0_mean: 556.83\n",
      "mean_ly_14_2017: 551.38\n",
      "mean_364_2017: 496.60\n",
      "item_mean_182_2017: 482.07\n",
      "l2y_1d_d0: 457.39\n",
      "mean_ly_21_2017: 449.35\n",
      "promo_60_2017: 405.74\n",
      "ly_1d_d0: 403.66\n",
      "promo_7: 206.64\n",
      "promo_14: 99.07\n",
      "promo_9: 73.60\n",
      "promo_2: 69.49\n",
      "promo_15: 60.81\n",
      "promo_5: 28.00\n",
      "promo_10: 24.63\n",
      "promo_3: 23.19\n",
      "promo_8: 16.49\n",
      "promo_4: 14.33\n",
      "promo_11: 13.10\n",
      "promo_6: 11.79\n",
      "promo_12: 9.54\n",
      "promo_13: 6.73\n",
      "promo_1: 6.59 \n",
      "2018-01-04 14:08:23,011 __main__ 61 [INFO]    [<module>] mean_7_2017: 54966.97\n",
      "mean_14_2017: 53449.86\n",
      "mean_42_2017: 17466.03\n",
      "mean_21_2017: 6195.68\n",
      "promo_0: 4786.38\n",
      "dow_26_0_mean: 4695.80\n",
      "mean_3_2017: 3515.54\n",
      "dow_8_0_mean: 3297.29\n",
      "dow_13_0_mean: 2820.91\n",
      "dow_52_0_mean: 2275.05\n",
      "day_1_2017: 1646.07\n",
      "mean_91_2017: 1390.68\n",
      "dow_4_0_mean: 1258.72\n",
      "mean_30_2017: 1100.88\n",
      "mean_182_2017: 1073.54\n",
      "item_mean_7_2017: 968.49\n",
      "promo_14_2017: 877.60\n",
      "mean_60_2017: 823.54\n",
      "dow_1_0_mean: 740.27\n",
      "item_dow_4_0_mean: 723.10\n",
      "mean_ly_n16d_2017: 723.00\n",
      "item_mean_21_2017: 662.46\n",
      "dow_ly3w_0_mean: 651.98\n",
      "item_day_1_2017: 651.14\n",
      "promo_140_2017: 649.65\n",
      "mean_ly_7_2017: 649.41\n",
      "dow_ly8w_0_mean: 620.89\n",
      "item_dow_52_0_mean: 604.68\n",
      "item_dow_13_0_mean: 594.33\n",
      "mean_140_2017: 587.80\n",
      "item_mean_91_2017: 587.37\n",
      "item_mean_42_2017: 580.70\n",
      "item_mean_364_2017: 569.88\n",
      "mean_ly_30_2017: 563.48\n",
      "item_dow_26_0_mean: 556.83\n",
      "mean_ly_14_2017: 551.38\n",
      "mean_364_2017: 496.60\n",
      "item_mean_182_2017: 482.07\n",
      "l2y_1d_d0: 457.39\n",
      "mean_ly_21_2017: 449.35\n",
      "promo_60_2017: 405.74\n",
      "ly_1d_d0: 403.66\n",
      "promo_7: 206.64\n",
      "promo_14: 99.07\n",
      "promo_9: 73.60\n",
      "promo_2: 69.49\n",
      "promo_15: 60.81\n",
      "promo_5: 28.00\n",
      "promo_10: 24.63\n",
      "promo_3: 23.19\n",
      "promo_8: 16.49\n",
      "promo_4: 14.33\n",
      "promo_11: 13.10\n",
      "promo_6: 11.79\n",
      "promo_12: 9.54\n",
      "promo_13: 6.73\n",
      "promo_1: 6.59 \n",
      "2018-01-04 14:08:23,011 __main__ 61 [INFO]    [<module>] mean_7_2017: 54966.97\n",
      "mean_14_2017: 53449.86\n",
      "mean_42_2017: 17466.03\n",
      "mean_21_2017: 6195.68\n",
      "promo_0: 4786.38\n",
      "dow_26_0_mean: 4695.80\n",
      "mean_3_2017: 3515.54\n",
      "dow_8_0_mean: 3297.29\n",
      "dow_13_0_mean: 2820.91\n",
      "dow_52_0_mean: 2275.05\n",
      "day_1_2017: 1646.07\n",
      "mean_91_2017: 1390.68\n",
      "dow_4_0_mean: 1258.72\n",
      "mean_30_2017: 1100.88\n",
      "mean_182_2017: 1073.54\n",
      "item_mean_7_2017: 968.49\n",
      "promo_14_2017: 877.60\n",
      "mean_60_2017: 823.54\n",
      "dow_1_0_mean: 740.27\n",
      "item_dow_4_0_mean: 723.10\n",
      "mean_ly_n16d_2017: 723.00\n",
      "item_mean_21_2017: 662.46\n",
      "dow_ly3w_0_mean: 651.98\n",
      "item_day_1_2017: 651.14\n",
      "promo_140_2017: 649.65\n",
      "mean_ly_7_2017: 649.41\n",
      "dow_ly8w_0_mean: 620.89\n",
      "item_dow_52_0_mean: 604.68\n",
      "item_dow_13_0_mean: 594.33\n",
      "mean_140_2017: 587.80\n",
      "item_mean_91_2017: 587.37\n",
      "item_mean_42_2017: 580.70\n",
      "item_mean_364_2017: 569.88\n",
      "mean_ly_30_2017: 563.48\n",
      "item_dow_26_0_mean: 556.83\n",
      "mean_ly_14_2017: 551.38\n",
      "mean_364_2017: 496.60\n",
      "item_mean_182_2017: 482.07\n",
      "l2y_1d_d0: 457.39\n",
      "mean_ly_21_2017: 449.35\n",
      "promo_60_2017: 405.74\n",
      "ly_1d_d0: 403.66\n",
      "promo_7: 206.64\n",
      "promo_14: 99.07\n",
      "promo_9: 73.60\n",
      "promo_2: 69.49\n",
      "promo_15: 60.81\n",
      "promo_5: 28.00\n",
      "promo_10: 24.63\n",
      "promo_3: 23.19\n",
      "promo_8: 16.49\n",
      "promo_4: 14.33\n",
      "promo_11: 13.10\n",
      "promo_6: 11.79\n",
      "promo_12: 9.54\n",
      "promo_13: 6.73\n",
      "promo_1: 6.59 \n",
      "2018-01-04 14:08:23,011 __main__ 61 [INFO]    [<module>] mean_7_2017: 54966.97\n",
      "mean_14_2017: 53449.86\n",
      "mean_42_2017: 17466.03\n",
      "mean_21_2017: 6195.68\n",
      "promo_0: 4786.38\n",
      "dow_26_0_mean: 4695.80\n",
      "mean_3_2017: 3515.54\n",
      "dow_8_0_mean: 3297.29\n",
      "dow_13_0_mean: 2820.91\n",
      "dow_52_0_mean: 2275.05\n",
      "day_1_2017: 1646.07\n",
      "mean_91_2017: 1390.68\n",
      "dow_4_0_mean: 1258.72\n",
      "mean_30_2017: 1100.88\n",
      "mean_182_2017: 1073.54\n",
      "item_mean_7_2017: 968.49\n",
      "promo_14_2017: 877.60\n",
      "mean_60_2017: 823.54\n",
      "dow_1_0_mean: 740.27\n",
      "item_dow_4_0_mean: 723.10\n",
      "mean_ly_n16d_2017: 723.00\n",
      "item_mean_21_2017: 662.46\n",
      "dow_ly3w_0_mean: 651.98\n",
      "item_day_1_2017: 651.14\n",
      "promo_140_2017: 649.65\n",
      "mean_ly_7_2017: 649.41\n",
      "dow_ly8w_0_mean: 620.89\n",
      "item_dow_52_0_mean: 604.68\n",
      "item_dow_13_0_mean: 594.33\n",
      "mean_140_2017: 587.80\n",
      "item_mean_91_2017: 587.37\n",
      "item_mean_42_2017: 580.70\n",
      "item_mean_364_2017: 569.88\n",
      "mean_ly_30_2017: 563.48\n",
      "item_dow_26_0_mean: 556.83\n",
      "mean_ly_14_2017: 551.38\n",
      "mean_364_2017: 496.60\n",
      "item_mean_182_2017: 482.07\n",
      "l2y_1d_d0: 457.39\n",
      "mean_ly_21_2017: 449.35\n",
      "promo_60_2017: 405.74\n",
      "ly_1d_d0: 403.66\n",
      "promo_7: 206.64\n",
      "promo_14: 99.07\n",
      "promo_9: 73.60\n",
      "promo_2: 69.49\n",
      "promo_15: 60.81\n",
      "promo_5: 28.00\n",
      "promo_10: 24.63\n",
      "promo_3: 23.19\n",
      "promo_8: 16.49\n",
      "promo_4: 14.33\n",
      "promo_11: 13.10\n",
      "promo_6: 11.79\n",
      "promo_12: 9.54\n",
      "promo_13: 6.73\n",
      "promo_1: 6.59 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\ttraining's l2: 0.189965\tvalid_1's l2: 0.181778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "139"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0 \n",
    "\n",
    "print(\"=\" * 70)\n",
    "logger.info(\"Step %d\" % (i+1))\n",
    "print(\"=\" * 70)\n",
    "features_t = features_all.copy()\n",
    "\n",
    "for j in range(16):\n",
    "    if j != i:\n",
    "        features_t.remove('ly_1d_d{}'.format(j))\n",
    "        features_t.remove('l2y_1d_d{}'.format(j))\n",
    "\n",
    "for j in range(7):\n",
    "    if j != i%7:\n",
    "        features_t.remove('dow_1_{}_mean'.format(j))\n",
    "        features_t.remove('dow_4_{}_mean'.format(j))\n",
    "        features_t.remove('dow_8_{}_mean'.format(j))\n",
    "        features_t.remove('dow_13_{}_mean'.format(j))\n",
    "        features_t.remove('dow_26_{}_mean'.format(j))\n",
    "        features_t.remove('dow_52_{}_mean'.format(j))\n",
    "        features_t.remove('dow_ly3w_{}_mean'.format(j))\n",
    "        features_t.remove('dow_ly8w_{}_mean'.format(j))\n",
    "\n",
    "        features_t.remove('item_dow_4_{}_mean'.format(j))\n",
    "        features_t.remove('item_dow_13_{}_mean'.format(j))\n",
    "        features_t.remove('item_dow_26_{}_mean'.format(j))\n",
    "        features_t.remove('item_dow_52_{}_mean'.format(j))\n",
    "\n",
    "\n",
    "X_train = X_train_allF[features_t]\n",
    "X_val = X_val_allF[features_t]\n",
    "X_test = X_test_allF[features_t]\n",
    "\n",
    "dtrain = lgb.Dataset(\n",
    "    X_train, label=y_train[:, i],\n",
    "    categorical_feature=cate_vars,\n",
    "    weight=pd.concat([items[\"perishable\"]]) * 0.25 + 1\n",
    ")\n",
    "\n",
    "if ((param_1 == \"val\") or (param_1 == \"1s\")):\n",
    "    dval = lgb.Dataset(\n",
    "         X_val, label=y_val[:, i], reference=dtrain,\n",
    "         weight=items_val[\"perishable\"] * 0.25 + 1,\n",
    "         categorical_feature=cate_vars)\n",
    "\n",
    "    bst = lgb.train(\n",
    "        params, dtrain, num_boost_round=MAX_ROUNDS,\n",
    "        valid_sets=[dtrain, dval], early_stopping_rounds=50,\n",
    "        verbose_eval=100\n",
    "    )\n",
    "\n",
    "else:\n",
    "\n",
    "    bst = lgb.train(\n",
    "        params, dtrain, num_boost_round=MAX_ROUNDS,\n",
    "        valid_sets=[dtrain], early_stopping_rounds=50, verbose_eval=100\n",
    "    )\n",
    "\n",
    "logger.info(\"\\n\".join((\"%s: %.2f\" % x) for x in sorted(\n",
    "    zip(X_train.columns, bst.feature_importance(\"gain\")),\n",
    "    key=lambda x: x[1], reverse=True\n",
    ")))\n",
    "\n",
    "test_pred.append(bst.predict(\n",
    "    X_test, num_iteration=bst.best_iteration or MAX_ROUNDS))\n",
    "\n",
    "if ((param_1 == \"val\") or (param_1 == \"1s\")):\n",
    "    val_pred.append(bst.predict(\n",
    "        X_val, num_iteration=bst.best_iteration or MAX_ROUNDS))\n",
    "\n",
    "del X_train, y_train\n",
    "del dtrain\n",
    "gc.collect()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
