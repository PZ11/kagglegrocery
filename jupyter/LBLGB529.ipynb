{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"LGBM Starter\n",
    "\n",
    "This is watered-down version of one of my earlier scripts. \n",
    "Only very basic features are retained so hopefully it won't ruin the fun for you.\n",
    "\"\"\"\n",
    "from datetime import date, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "\n",
    "df_train = pd.read_csv(\n",
    "    '../../input/train_small.csv', usecols=[0, 1, 2, 3, 4],\n",
    "    dtype={'onpromotion': bool},\n",
    "    converters={'unit_sales': lambda u: np.log1p(float(u)) if float(u) > 0 else 0},\n",
    "    parse_dates=[\"date\"],\n",
    "    skiprows=range(1, 21410)  # 2016-01-01\n",
    ")\n",
    "\n",
    "items = pd.read_csv(\"../../input/items.csv\",).set_index(\"item_nbr\")\n",
    "#df_train = df_train.loc[(df_train.store_nbr == 9), ]\n",
    "\n",
    "df_test = pd.read_csv(\n",
    "    \"../../input/test_small.csv\", usecols=[  1, 2, 3, 4],\n",
    "    dtype={'onpromotion': bool},\n",
    "    parse_dates=[\"date\"]  # , date_parser=parser\n",
    ").set_index(\n",
    "    ['store_nbr', 'item_nbr', 'date']\n",
    ")\n",
    "\n",
    "\n",
    "df_train = df_train.loc[(df_train.store_nbr == 9), ]\n",
    "#df_test = df_test.loc[(df_test.store_nbr == 9), ].set_index(\n",
    "#    ['store_nbr', 'item_nbr', 'date']\n",
    "#)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>unit_sales</th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>2.890372</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>2016-01-06</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>2016-01-07</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>2016-01-10</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>2016-01-11</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>2016-01-12</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>2016-01-14</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>2016-01-16</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>2016-01-17</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>2016-01-18</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>2016-01-19</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>2016-01-20</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>2016-01-21</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>2016-01-23</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>2016-01-24</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>2016-01-25</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>2016-01-26</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>2016-01-27</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>2016-01-28</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>2016-01-29</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>2016-01-30</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>2016-01-31</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>2016-02-02</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13662</th>\n",
       "      <td>2017-07-16</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13685</th>\n",
       "      <td>2017-07-17</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13710</th>\n",
       "      <td>2017-07-18</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13737</th>\n",
       "      <td>2017-07-19</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13763</th>\n",
       "      <td>2017-07-20</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13789</th>\n",
       "      <td>2017-07-21</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13814</th>\n",
       "      <td>2017-07-22</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13839</th>\n",
       "      <td>2017-07-23</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13866</th>\n",
       "      <td>2017-07-24</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13892</th>\n",
       "      <td>2017-07-25</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13918</th>\n",
       "      <td>2017-07-26</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13941</th>\n",
       "      <td>2017-07-27</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13964</th>\n",
       "      <td>2017-07-28</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13988</th>\n",
       "      <td>2017-07-29</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14013</th>\n",
       "      <td>2017-07-30</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14040</th>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14065</th>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14091</th>\n",
       "      <td>2017-08-02</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14117</th>\n",
       "      <td>2017-08-03</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14143</th>\n",
       "      <td>2017-08-04</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14167</th>\n",
       "      <td>2017-08-05</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14191</th>\n",
       "      <td>2017-08-06</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14215</th>\n",
       "      <td>2017-08-07</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14238</th>\n",
       "      <td>2017-08-08</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14263</th>\n",
       "      <td>2017-08-09</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14290</th>\n",
       "      <td>2017-08-10</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14310</th>\n",
       "      <td>2017-08-11</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14359</th>\n",
       "      <td>2017-08-13</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14382</th>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14407</th>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>573 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  store_nbr  item_nbr  unit_sales  onpromotion\n",
       "0     2016-01-02          9    103501    2.564949        False\n",
       "26    2016-01-03          9    103501    2.890372        False\n",
       "51    2016-01-04          9    103501    2.079442        False\n",
       "78    2016-01-05          9    103501    2.302585        False\n",
       "103   2016-01-06          9    103501    1.386294        False\n",
       "125   2016-01-07          9    103501    1.945910        False\n",
       "179   2016-01-10          9    103501    0.693147        False\n",
       "201   2016-01-11          9    103501    1.386294        False\n",
       "222   2016-01-12          9    103501    1.386294        False\n",
       "246   2016-01-13          9    103501    2.079442        False\n",
       "270   2016-01-14          9    103501    1.609438        False\n",
       "294   2016-01-15          9    103501    1.609438        False\n",
       "319   2016-01-16          9    103501    2.079442        False\n",
       "345   2016-01-17          9    103501    2.197225        False\n",
       "370   2016-01-18          9    103501    1.609438        False\n",
       "394   2016-01-19          9    103501    2.197225        False\n",
       "418   2016-01-20          9    103501    0.693147        False\n",
       "441   2016-01-21          9    103501    1.386294        False\n",
       "464   2016-01-22          9    103501    1.609438        False\n",
       "483   2016-01-23          9    103501    2.302585        False\n",
       "506   2016-01-24          9    103501    1.609438        False\n",
       "530   2016-01-25          9    103501    1.791759        False\n",
       "553   2016-01-26          9    103501    1.609438        False\n",
       "577   2016-01-27          9    103501    1.098612        False\n",
       "599   2016-01-28          9    103501    0.693147        False\n",
       "621   2016-01-29          9    103501    1.386294        False\n",
       "642   2016-01-30          9    103501    2.302585        False\n",
       "665   2016-01-31          9    103501    2.564949        False\n",
       "691   2016-02-01          9    103501    2.302585        False\n",
       "716   2016-02-02          9    103501    0.693147        False\n",
       "...          ...        ...       ...         ...          ...\n",
       "13662 2017-07-16          9    103501    2.079442        False\n",
       "13685 2017-07-17          9    103501    2.397895        False\n",
       "13710 2017-07-18          9    103501    2.079442        False\n",
       "13737 2017-07-19          9    103501    1.098612        False\n",
       "13763 2017-07-20          9    103501    1.609438        False\n",
       "13789 2017-07-21          9    103501    0.693147        False\n",
       "13814 2017-07-22          9    103501    1.098612        False\n",
       "13839 2017-07-23          9    103501    2.302585        False\n",
       "13866 2017-07-24          9    103501    1.791759        False\n",
       "13892 2017-07-25          9    103501    0.693147        False\n",
       "13918 2017-07-26          9    103501    1.386294        False\n",
       "13941 2017-07-27          9    103501    1.945910        False\n",
       "13964 2017-07-28          9    103501    1.791759        False\n",
       "13988 2017-07-29          9    103501    1.945910        False\n",
       "14013 2017-07-30          9    103501    2.397895        False\n",
       "14040 2017-07-31          9    103501    1.945910        False\n",
       "14065 2017-08-01          9    103501    1.609438        False\n",
       "14091 2017-08-02          9    103501    1.945910        False\n",
       "14117 2017-08-03          9    103501    2.302585        False\n",
       "14143 2017-08-04          9    103501    1.386294        False\n",
       "14167 2017-08-05          9    103501    1.791759        False\n",
       "14191 2017-08-06          9    103501    2.079442        False\n",
       "14215 2017-08-07          9    103501    0.693147        False\n",
       "14238 2017-08-08          9    103501    2.197225        False\n",
       "14263 2017-08-09          9    103501    2.197225        False\n",
       "14290 2017-08-10          9    103501    0.693147        False\n",
       "14310 2017-08-11          9    103501    1.386294        False\n",
       "14359 2017-08-13          9    103501    1.098612        False\n",
       "14382 2017-08-14          9    103501    1.791759        False\n",
       "14407 2017-08-15          9    103501    2.079442        False\n",
       "\n",
       "[573 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_2017 = df_train[df_train.date.isin(\n",
    "    pd.date_range(\"2017-05-31\", periods=7 * 11))].copy()\n",
    "#del df_train\n",
    "\n",
    "promo_2017_train = df_2017.set_index(\n",
    "    [\"store_nbr\", \"item_nbr\", \"date\"])[[\"onpromotion\"]].unstack(\n",
    "        level=-1).fillna(False)\n",
    "promo_2017_train.columns = promo_2017_train.columns.get_level_values(1)\n",
    "promo_2017_test = df_test[[\"onpromotion\"]].unstack(level=-1).fillna(False)\n",
    "promo_2017_test.columns = promo_2017_test.columns.get_level_values(1)\n",
    "promo_2017_test = promo_2017_test.reindex(promo_2017_train.index).fillna(False)\n",
    "promo_2017 = pd.concat([promo_2017_train, promo_2017_test], axis=1)\n",
    "#del promo_2017_test, promo_2017_train\n",
    "\n",
    "df_2017 = df_2017.set_index(\n",
    "    [\"store_nbr\", \"item_nbr\", \"date\"])[[\"unit_sales\"]].unstack(\n",
    "        level=-1).fillna(0)\n",
    "df_2017.columns = df_2017.columns.get_level_values(1)\n",
    "\n",
    "items = items.reindex(df_2017.index.get_level_values(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>2017-05-31 00:00:00</th>\n",
       "      <th>2017-06-01 00:00:00</th>\n",
       "      <th>2017-06-02 00:00:00</th>\n",
       "      <th>2017-06-03 00:00:00</th>\n",
       "      <th>2017-06-04 00:00:00</th>\n",
       "      <th>2017-06-05 00:00:00</th>\n",
       "      <th>2017-06-06 00:00:00</th>\n",
       "      <th>2017-06-07 00:00:00</th>\n",
       "      <th>2017-06-08 00:00:00</th>\n",
       "      <th>2017-06-09 00:00:00</th>\n",
       "      <th>...</th>\n",
       "      <th>2017-08-05 00:00:00</th>\n",
       "      <th>2017-08-06 00:00:00</th>\n",
       "      <th>2017-08-07 00:00:00</th>\n",
       "      <th>2017-08-08 00:00:00</th>\n",
       "      <th>2017-08-09 00:00:00</th>\n",
       "      <th>2017-08-10 00:00:00</th>\n",
       "      <th>2017-08-11 00:00:00</th>\n",
       "      <th>2017-08-13 00:00:00</th>\n",
       "      <th>2017-08-14 00:00:00</th>\n",
       "      <th>2017-08-15 00:00:00</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <th>103501</th>\n",
       "      <td>1.94591</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>...</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "date                2017-05-31  2017-06-01  2017-06-02  2017-06-03  \\\n",
       "store_nbr item_nbr                                                   \n",
       "9         103501       1.94591    2.079442    2.079442    2.484907   \n",
       "\n",
       "date                2017-06-04  2017-06-05  2017-06-06  2017-06-07  \\\n",
       "store_nbr item_nbr                                                   \n",
       "9         103501      2.772589    1.386294    1.791759    1.791759   \n",
       "\n",
       "date                2017-06-08  2017-06-09     ...      2017-08-05  \\\n",
       "store_nbr item_nbr                             ...                   \n",
       "9         103501      1.098612    1.386294     ...        1.791759   \n",
       "\n",
       "date                2017-08-06  2017-08-07  2017-08-08  2017-08-09  \\\n",
       "store_nbr item_nbr                                                   \n",
       "9         103501      2.079442    0.693147    2.197225    2.197225   \n",
       "\n",
       "date                2017-08-10  2017-08-11  2017-08-13  2017-08-14  2017-08-15  \n",
       "store_nbr item_nbr                                                              \n",
       "9         103501      0.693147    1.386294    1.098612    1.791759    2.079442  \n",
       "\n",
       "[1 rows x 76 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_timespan(df, dt, minus, periods):\n",
    "    return df[\n",
    "        pd.date_range(dt - timedelta(days=minus), periods=periods)\n",
    "    ]\n",
    "\n",
    "\n",
    "def prepare_dataset(t2017, is_train=True):\n",
    "    X = pd.DataFrame({\n",
    "        \"mean_3_2017\": get_timespan(df_2017, t2017, 3, 3).mean(axis=1).values,\n",
    "        \"mean_7_2017\": get_timespan(df_2017, t2017, 7, 7).mean(axis=1).values,\n",
    "        \"mean_14_2017\": get_timespan(df_2017, t2017, 14, 14).mean(axis=1).values,\n",
    "        \"promo_14_2017\": get_timespan(promo_2017, t2017, 14, 14).sum(axis=1).values\n",
    "    })\n",
    "    for i in range(16):\n",
    "        X[\"promo_{}\".format(i)] = promo_2017[\n",
    "            t2017 + timedelta(days=i)].values.astype(np.uint8)\n",
    "    if is_train:\n",
    "        y = df_2017[\n",
    "            pd.date_range(t2017, periods=16)\n",
    "        ].values\n",
    "        return X, y\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing dataset...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Preparing dataset...\")\n",
    "t2017 = date(2017, 6, 21)\n",
    "X_l, y_l = [], []\n",
    "for i in range(4):\n",
    "    delta = timedelta(days=7 * i)\n",
    "    X_tmp, y_tmp = prepare_dataset(\n",
    "        t2017 + delta\n",
    "    )\n",
    "    X_l.append(X_tmp)\n",
    "    y_l.append(y_tmp)\n",
    "X_train = pd.concat(X_l, axis=0)\n",
    "y_train = np.concatenate(y_l, axis=0)\n",
    "#del X_l, y_l\n",
    "X_val, y_val = prepare_dataset(date(2017, 7, 26))\n",
    "#X_test = prepare_dataset(date(2017, 8, 16), is_train=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.60943791,  1.60943791,  1.60943791,  2.30258509,  1.94591015,\n",
       "         1.60943791,  1.60943791,  1.60943791,  1.38629436,  2.07944154,\n",
       "         2.19722458,  2.94443898,  1.60943791,  2.7080502 ,  1.60943791,\n",
       "         2.19722458],\n",
       "       [ 1.60943791,  1.38629436,  2.07944154,  2.19722458,  2.94443898,\n",
       "         1.60943791,  2.7080502 ,  1.60943791,  2.19722458,  0.69314718,\n",
       "         0.69314718,  0.69314718,  1.79175947,  1.94591015,  2.30258509,\n",
       "         1.38629436],\n",
       "       [ 1.60943791,  2.19722458,  0.69314718,  0.69314718,  0.69314718,\n",
       "         1.79175947,  1.94591015,  2.30258509,  1.38629436,  0.69314718,\n",
       "         2.19722458,  2.07944154,  2.39789527,  2.07944154,  1.09861229,\n",
       "         1.60943791],\n",
       "       [ 2.30258509,  1.38629436,  0.69314718,  2.19722458,  2.07944154,\n",
       "         2.39789527,  2.07944154,  1.09861229,  1.60943791,  0.69314718,\n",
       "         1.09861229,  2.30258509,  1.79175947,  0.69314718,  1.38629436,\n",
       "         1.94591015]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and predicting models...\n",
      "==================================================\n",
      "Step 1\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 3673.15\tvalid_1's l2: 3695.72\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's l2: 0.397393\tvalid_1's l2: 0.350666\n",
      "mean_14_2017: 0.00\n",
      "mean_3_2017: 0.00\n",
      "mean_7_2017: 0.00\n",
      "promo_14_2017: 0.00\n",
      "promo_0: 0.00\n",
      "promo_1: 0.00\n",
      "promo_2: 0.00\n",
      "promo_3: 0.00\n",
      "promo_4: 0.00\n",
      "promo_5: 0.00\n",
      "promo_6: 0.00\n",
      "promo_7: 0.00\n",
      "promo_8: 0.00\n",
      "promo_9: 0.00\n",
      "promo_10: 0.00\n",
      "promo_11: 0.00\n",
      "promo_12: 0.00\n",
      "promo_13: 0.00\n",
      "promo_14: 0.00\n",
      "promo_15: 0.00\n",
      "==================================================\n",
      "Step 2\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 3899.8\tvalid_1's l2: 3922.85\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's l2: 0.360099\tvalid_1's l2: 0.364542\n",
      "mean_14_2017: 0.00\n",
      "mean_3_2017: 0.00\n",
      "mean_7_2017: 0.00\n",
      "promo_14_2017: 0.00\n",
      "promo_0: 0.00\n",
      "promo_1: 0.00\n",
      "promo_2: 0.00\n",
      "promo_3: 0.00\n",
      "promo_4: 0.00\n",
      "promo_5: 0.00\n",
      "promo_6: 0.00\n",
      "promo_7: 0.00\n",
      "promo_8: 0.00\n",
      "promo_9: 0.00\n",
      "promo_10: 0.00\n",
      "promo_11: 0.00\n",
      "promo_12: 0.00\n",
      "promo_13: 0.00\n",
      "promo_14: 0.00\n",
      "promo_15: 0.00\n",
      "==================================================\n",
      "Step 3\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 3505.4\tvalid_1's l2: 3490.24\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's l2: 0.412447\tvalid_1's l2: 0.390629\n",
      "mean_14_2017: 0.00\n",
      "mean_3_2017: 0.00\n",
      "mean_7_2017: 0.00\n",
      "promo_14_2017: 0.00\n",
      "promo_0: 0.00\n",
      "promo_1: 0.00\n",
      "promo_2: 0.00\n",
      "promo_3: 0.00\n",
      "promo_4: 0.00\n",
      "promo_5: 0.00\n",
      "promo_6: 0.00\n",
      "promo_7: 0.00\n",
      "promo_8: 0.00\n",
      "promo_9: 0.00\n",
      "promo_10: 0.00\n",
      "promo_11: 0.00\n",
      "promo_12: 0.00\n",
      "promo_13: 0.00\n",
      "promo_14: 0.00\n",
      "promo_15: 0.00\n",
      "==================================================\n",
      "Step 4\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 6739.65\tvalid_1's l2: 6749.62\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's l2: 0.340559\tvalid_1's l2: 0.514081\n",
      "mean_14_2017: 0.00\n",
      "mean_3_2017: 0.00\n",
      "mean_7_2017: 0.00\n",
      "promo_14_2017: 0.00\n",
      "promo_0: 0.00\n",
      "promo_1: 0.00\n",
      "promo_2: 0.00\n",
      "promo_3: 0.00\n",
      "promo_4: 0.00\n",
      "promo_5: 0.00\n",
      "promo_6: 0.00\n",
      "promo_7: 0.00\n",
      "promo_8: 0.00\n",
      "promo_9: 0.00\n",
      "promo_10: 0.00\n",
      "promo_11: 0.00\n",
      "promo_12: 0.00\n",
      "promo_13: 0.00\n",
      "promo_14: 0.00\n",
      "promo_15: 0.00\n",
      "==================================================\n",
      "Step 5\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 6785.6\tvalid_1's l2: 6767.81\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's l2: 0.580148\tvalid_1's l2: 0.374773\n",
      "mean_14_2017: 0.00\n",
      "mean_3_2017: 0.00\n",
      "mean_7_2017: 0.00\n",
      "promo_14_2017: 0.00\n",
      "promo_0: 0.00\n",
      "promo_1: 0.00\n",
      "promo_2: 0.00\n",
      "promo_3: 0.00\n",
      "promo_4: 0.00\n",
      "promo_5: 0.00\n",
      "promo_6: 0.00\n",
      "promo_7: 0.00\n",
      "promo_8: 0.00\n",
      "promo_9: 0.00\n",
      "promo_10: 0.00\n",
      "promo_11: 0.00\n",
      "promo_12: 0.00\n",
      "promo_13: 0.00\n",
      "promo_14: 0.00\n",
      "promo_15: 0.00\n",
      "==================================================\n",
      "Step 6\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 4877.32\tvalid_1's l2: 4856.48\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's l2: 0.411215\tvalid_1's l2: 0.569026\n",
      "mean_14_2017: 0.00\n",
      "mean_3_2017: 0.00\n",
      "mean_7_2017: 0.00\n",
      "promo_14_2017: 0.00\n",
      "promo_0: 0.00\n",
      "promo_1: 0.00\n",
      "promo_2: 0.00\n",
      "promo_3: 0.00\n",
      "promo_4: 0.00\n",
      "promo_5: 0.00\n",
      "promo_6: 0.00\n",
      "promo_7: 0.00\n",
      "promo_8: 0.00\n",
      "promo_9: 0.00\n",
      "promo_10: 0.00\n",
      "promo_11: 0.00\n",
      "promo_12: 0.00\n",
      "promo_13: 0.00\n",
      "promo_14: 0.00\n",
      "promo_15: 0.00\n",
      "==================================================\n",
      "Step 7\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 4954.79\tvalid_1's l2: 4909.23\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's l2: 0.403757\tvalid_1's l2: 0.533882\n",
      "mean_14_2017: 0.00\n",
      "mean_3_2017: 0.00\n",
      "mean_7_2017: 0.00\n",
      "promo_14_2017: 0.00\n",
      "promo_0: 0.00\n",
      "promo_1: 0.00\n",
      "promo_2: 0.00\n",
      "promo_3: 0.00\n",
      "promo_4: 0.00\n",
      "promo_5: 0.00\n",
      "promo_6: 0.00\n",
      "promo_7: 0.00\n",
      "promo_8: 0.00\n",
      "promo_9: 0.00\n",
      "promo_10: 0.00\n",
      "promo_11: 0.00\n",
      "promo_12: 0.00\n",
      "promo_13: 0.00\n",
      "promo_14: 0.00\n",
      "promo_15: 0.00\n",
      "==================================================\n",
      "Step 8\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 3815.92\tvalid_1's l2: 3783.75\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's l2: 0.363278\tvalid_1's l2: 0.453424\n",
      "mean_14_2017: 0.00\n",
      "mean_3_2017: 0.00\n",
      "mean_7_2017: 0.00\n",
      "promo_14_2017: 0.00\n",
      "promo_0: 0.00\n",
      "promo_1: 0.00\n",
      "promo_2: 0.00\n",
      "promo_3: 0.00\n",
      "promo_4: 0.00\n",
      "promo_5: 0.00\n",
      "promo_6: 0.00\n",
      "promo_7: 0.00\n",
      "promo_8: 0.00\n",
      "promo_9: 0.00\n",
      "promo_10: 0.00\n",
      "promo_11: 0.00\n",
      "promo_12: 0.00\n",
      "promo_13: 0.00\n",
      "promo_14: 0.00\n",
      "promo_15: 0.00\n",
      "==================================================\n",
      "Step 9\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 3765.41\tvalid_1's l2: 3753.75\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's l2: 0.329284\tvalid_1's l2: 0.330791\n",
      "mean_14_2017: 0.00\n",
      "mean_3_2017: 0.00\n",
      "mean_7_2017: 0.00\n",
      "promo_14_2017: 0.00\n",
      "promo_0: 0.00\n",
      "promo_1: 0.00\n",
      "promo_2: 0.00\n",
      "promo_3: 0.00\n",
      "promo_4: 0.00\n",
      "promo_5: 0.00\n",
      "promo_6: 0.00\n",
      "promo_7: 0.00\n",
      "promo_8: 0.00\n",
      "promo_9: 0.00\n",
      "promo_10: 0.00\n",
      "promo_11: 0.00\n",
      "promo_12: 0.00\n",
      "promo_13: 0.00\n",
      "promo_14: 0.00\n",
      "promo_15: 0.00\n",
      "==================================================\n",
      "Step 10\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zyp/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1030: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 3366.29\tvalid_1's l2: 3360.32\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's l2: 0.387169\tvalid_1's l2: 0.334072\n",
      "mean_14_2017: 0.00\n",
      "mean_3_2017: 0.00\n",
      "mean_7_2017: 0.00\n",
      "promo_14_2017: 0.00\n",
      "promo_0: 0.00\n",
      "promo_1: 0.00\n",
      "promo_2: 0.00\n",
      "promo_3: 0.00\n",
      "promo_4: 0.00\n",
      "promo_5: 0.00\n",
      "promo_6: 0.00\n",
      "promo_7: 0.00\n",
      "promo_8: 0.00\n",
      "promo_9: 0.00\n",
      "promo_10: 0.00\n",
      "promo_11: 0.00\n",
      "promo_12: 0.00\n",
      "promo_13: 0.00\n",
      "promo_14: 0.00\n",
      "promo_15: 0.00\n",
      "==================================================\n",
      "Step 11\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 6224.47\tvalid_1's l2: 6244.67\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's l2: 0.381792\tvalid_1's l2: 0.470667\n",
      "mean_14_2017: 0.00\n",
      "mean_3_2017: 0.00\n",
      "mean_7_2017: 0.00\n",
      "promo_14_2017: 0.00\n",
      "promo_0: 0.00\n",
      "promo_1: 0.00\n",
      "promo_2: 0.00\n",
      "promo_3: 0.00\n",
      "promo_4: 0.00\n",
      "promo_5: 0.00\n",
      "promo_6: 0.00\n",
      "promo_7: 0.00\n",
      "promo_8: 0.00\n",
      "promo_9: 0.00\n",
      "promo_10: 0.00\n",
      "promo_11: 0.00\n",
      "promo_12: 0.00\n",
      "promo_13: 0.00\n",
      "promo_14: 0.00\n",
      "promo_15: 0.00\n",
      "==================================================\n",
      "Step 12\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 6927.69\tvalid_1's l2: 6972.73\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's l2: 0.48364\tvalid_1's l2: 0.61864\n",
      "mean_14_2017: 0.00\n",
      "mean_3_2017: 0.00\n",
      "mean_7_2017: 0.00\n",
      "promo_14_2017: 0.00\n",
      "promo_0: 0.00\n",
      "promo_1: 0.00\n",
      "promo_2: 0.00\n",
      "promo_3: 0.00\n",
      "promo_4: 0.00\n",
      "promo_5: 0.00\n",
      "promo_6: 0.00\n",
      "promo_7: 0.00\n",
      "promo_8: 0.00\n",
      "promo_9: 0.00\n",
      "promo_10: 0.00\n",
      "promo_11: 0.00\n",
      "promo_12: 0.00\n",
      "promo_13: 0.00\n",
      "promo_14: 0.00\n",
      "promo_15: 0.00\n",
      "==================================================\n",
      "Step 13\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 5356.15\tvalid_1's l2: 5393.22\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's l2: 0.358276\tvalid_1's l2: 0.598475\n",
      "mean_14_2017: 0.00\n",
      "mean_3_2017: 0.00\n",
      "mean_7_2017: 0.00\n",
      "promo_14_2017: 0.00\n",
      "promo_0: 0.00\n",
      "promo_1: 0.00\n",
      "promo_2: 0.00\n",
      "promo_3: 0.00\n",
      "promo_4: 0.00\n",
      "promo_5: 0.00\n",
      "promo_6: 0.00\n",
      "promo_7: 0.00\n",
      "promo_8: 0.00\n",
      "promo_9: 0.00\n",
      "promo_10: 0.00\n",
      "promo_11: 0.00\n",
      "promo_12: 0.00\n",
      "promo_13: 0.00\n",
      "promo_14: 0.00\n",
      "promo_15: 0.00\n",
      "==================================================\n",
      "Step 14\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 4817.72\tvalid_1's l2: 4832.86\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's l2: 0.385955\tvalid_1's l2: 0.375597\n",
      "mean_14_2017: 0.00\n",
      "mean_3_2017: 0.00\n",
      "mean_7_2017: 0.00\n",
      "promo_14_2017: 0.00\n",
      "promo_0: 0.00\n",
      "promo_1: 0.00\n",
      "promo_2: 0.00\n",
      "promo_3: 0.00\n",
      "promo_4: 0.00\n",
      "promo_5: 0.00\n",
      "promo_6: 0.00\n",
      "promo_7: 0.00\n",
      "promo_8: 0.00\n",
      "promo_9: 0.00\n",
      "promo_10: 0.00\n",
      "promo_11: 0.00\n",
      "promo_12: 0.00\n",
      "promo_13: 0.00\n",
      "promo_14: 0.00\n",
      "promo_15: 0.00\n",
      "==================================================\n",
      "Step 15\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 3766.26\tvalid_1's l2: 3758.03\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's l2: 0.326361\tvalid_1's l2: 0.135522\n",
      "mean_14_2017: 0.00\n",
      "mean_3_2017: 0.00\n",
      "mean_7_2017: 0.00\n",
      "promo_14_2017: 0.00\n",
      "promo_0: 0.00\n",
      "promo_1: 0.00\n",
      "promo_2: 0.00\n",
      "promo_3: 0.00\n",
      "promo_4: 0.00\n",
      "promo_5: 0.00\n",
      "promo_6: 0.00\n",
      "promo_7: 0.00\n",
      "promo_8: 0.00\n",
      "promo_9: 0.00\n",
      "promo_10: 0.00\n",
      "promo_11: 0.00\n",
      "promo_12: 0.00\n",
      "promo_13: 0.00\n",
      "promo_14: 0.00\n",
      "promo_15: 0.00\n",
      "==================================================\n",
      "Step 16\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 3490.49\tvalid_1's l2: 3518.19\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's l2: 0.336827\tvalid_1's l2: 0.549353\n",
      "mean_14_2017: 0.00\n",
      "mean_3_2017: 0.00\n",
      "mean_7_2017: 0.00\n",
      "promo_14_2017: 0.00\n",
      "promo_0: 0.00\n",
      "promo_1: 0.00\n",
      "promo_2: 0.00\n",
      "promo_3: 0.00\n",
      "promo_4: 0.00\n",
      "promo_5: 0.00\n",
      "promo_6: 0.00\n",
      "promo_7: 0.00\n",
      "promo_8: 0.00\n",
      "promo_9: 0.00\n",
      "promo_10: 0.00\n",
      "promo_11: 0.00\n",
      "promo_12: 0.00\n",
      "promo_13: 0.00\n",
      "promo_14: 0.00\n",
      "promo_15: 0.00\n",
      "Validation mse: 2.35814225699\n",
      "Making submission...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Training and predicting models...\")\n",
    "params = {\n",
    "    'num_leaves': 2**5 - 1,\n",
    "    'objective': 'regression_l2',\n",
    "    'max_depth': 8,\n",
    "    'min_data_in_leaf': 50,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.75,\n",
    "    'bagging_fraction': 0.75,\n",
    "    'bagging_freq': 1,\n",
    "    'metric': 'l2',\n",
    "    'num_threads': 4\n",
    "}\n",
    "\n",
    "MAX_ROUNDS = 1000\n",
    "val_pred = []\n",
    "test_pred = []\n",
    "cate_vars = []\n",
    "for i in range(16):\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Step %d\" % (i+1))\n",
    "    print(\"=\" * 50)\n",
    "    dtrain = lgb.Dataset(\n",
    "        X_train, label=y_train[:, i],\n",
    "        categorical_feature=cate_vars,\n",
    "        weight=pd.concat([items[\"perishable\"]] * 4) * 0.25 + 1\n",
    "    )\n",
    "    dval = lgb.Dataset(\n",
    "        X_val, label=y_val[:, i], reference=dtrain,\n",
    "        weight=items[\"perishable\"] * 0.25 + 1,\n",
    "        categorical_feature=cate_vars)\n",
    "    bst = lgb.train(\n",
    "        params, dtrain, num_boost_round=MAX_ROUNDS,\n",
    "        valid_sets=[dtrain, dval], early_stopping_rounds=50, verbose_eval=50\n",
    "    )\n",
    "    print(\"\\n\".join((\"%s: %.2f\" % x) for x in sorted(\n",
    "        zip(X_train.columns, bst.feature_importance(\"gain\")),\n",
    "        key=lambda x: x[1], reverse=True\n",
    "    )))\n",
    "    val_pred.append(bst.predict(\n",
    "        X_val, num_iteration=bst.best_iteration or MAX_ROUNDS))\n",
    "#    test_pred.append(bst.predict(\n",
    "#        X_test, num_iteration=bst.best_iteration or MAX_ROUNDS))\n",
    "\n",
    "print(\"Validation mse:\", mean_squared_error(\n",
    "    y_val, np.array(val_pred).transpose()))\n",
    "\n",
    "print(\"Making submission...\")\n",
    "#y_test = np.array(test_pred).transpose()\n",
    "#df_preds = pd.DataFrame(\n",
    "#    y_test, index=df_2017.index,\n",
    "#    columns=pd.date_range(\"2017-08-16\", periods=16)\n",
    "#).stack().to_frame(\"unit_sales\")\n",
    "#df_preds.index.set_names([\"store_nbr\", \"item_nbr\", \"date\"], inplace=True)\n",
    "\n",
    "#submission = df_test[[\"id\"]].join(df_preds, how=\"left\").fillna(0)\n",
    "#submission[\"unit_sales\"] = np.clip(np.expm1(submission[\"unit_sales\"]), 0, 1000)\n",
    "#submission.to_csv('lgb.csv', float_format='%.4f', index=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_14_2017</th>\n",
       "      <th>mean_3_2017</th>\n",
       "      <th>mean_7_2017</th>\n",
       "      <th>promo_14_2017</th>\n",
       "      <th>promo_0</th>\n",
       "      <th>promo_1</th>\n",
       "      <th>promo_2</th>\n",
       "      <th>promo_3</th>\n",
       "      <th>promo_4</th>\n",
       "      <th>promo_5</th>\n",
       "      <th>promo_6</th>\n",
       "      <th>promo_7</th>\n",
       "      <th>promo_8</th>\n",
       "      <th>promo_9</th>\n",
       "      <th>promo_10</th>\n",
       "      <th>promo_11</th>\n",
       "      <th>promo_12</th>\n",
       "      <th>promo_13</th>\n",
       "      <th>promo_14</th>\n",
       "      <th>promo_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.601666</td>\n",
       "      <td>1.595831</td>\n",
       "      <td>1.326757</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_14_2017  mean_3_2017  mean_7_2017  promo_14_2017  promo_0  promo_1  \\\n",
       "0      1.601666     1.595831     1.326757              0        0        0   \n",
       "\n",
       "   promo_2  promo_3  promo_4  promo_5  promo_6  promo_7  promo_8  promo_9  \\\n",
       "0        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   promo_10  promo_11  promo_12  promo_13  promo_14  promo_15  \n",
       "0         0         0         0         0         0         0  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
