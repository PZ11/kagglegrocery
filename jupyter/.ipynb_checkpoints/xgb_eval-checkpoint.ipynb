{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-12-01 22:17:18,317 __main__ 29 [INFO][<module>] start \n",
      "2017-12-01 22:17:18,317 __main__ 29 [INFO][<module>] start \n",
      "2017-12-01 22:17:18,317 __main__ 29 [INFO][<module>] start \n",
      "2017-12-01 22:17:18,360 __main__ 61 [INFO][<module>] load data successful \n",
      "2017-12-01 22:17:18,360 __main__ 61 [INFO][<module>] load data successful \n",
      "2017-12-01 22:17:18,360 __main__ 61 [INFO][<module>] load data successful \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "from logging import StreamHandler, DEBUG, Formatter, FileHandler, getLogger\n",
    "\n",
    "import sklearn.metrics as skl_metrics\n",
    "import xgboost as xgb\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import math\n",
    "\n",
    "logger = getLogger(__name__)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "DIR = '../result_tmp/'\n",
    "\n",
    "log_fmt = Formatter('%(asctime)s %(name)s %(lineno)d [%(levelname)s][%(funcName)s] %(message)s ')\n",
    "handler = StreamHandler()\n",
    "handler.setLevel('INFO')\n",
    "handler.setFormatter(log_fmt)\n",
    "logger.addHandler(handler)\n",
    "\n",
    "handler = FileHandler(DIR + 'train.py.log', 'a')\n",
    "handler.setLevel(DEBUG)\n",
    "handler.setFormatter(log_fmt)\n",
    "logger.setLevel(DEBUG)\n",
    "logger.addHandler(handler)\n",
    "\n",
    "logger.info('start')\n",
    "\n",
    "def create_feature_map(features):\n",
    "    outfile = open('xgb.fmap', 'w')\n",
    "    for i, feat in enumerate(features):\n",
    "        outfile.write('{0}\\t{1}\\tq\\n'.format(i, feat))\n",
    "    outfile.close()\n",
    "\n",
    "def NWRMSLE(y, pred, weights=None):\n",
    "    err2 = skl_metrics.mean_squared_log_error(y, pred, sample_weight=weights)\n",
    "    return math.sqrt(err2)\n",
    "\n",
    "def NWRMSLE_A(y, pred, weights):\n",
    "    y = np.array(y)\n",
    "    pred = np.array(pred)\n",
    "    weights = np.array(weights)\n",
    "    weighted_errors = np.dot(np.square(np.log1p(pred) - np.log1p(y)), np.transpose(weights))\n",
    "    weights_sum = np.sum(weights)\n",
    "    return math.sqrt(weighted_errors/weights_sum)\n",
    "\n",
    "def NWRMSLE_lgb(pred, dtrain):\n",
    "    y = list(dtrain.get_label())\n",
    "    score = NWRMSLE(y, pred)\n",
    "    return 'NWRMSLE', score, False\n",
    "\n",
    "\n",
    "dtypes = {'item_nbr':'int32', 'store_nbr':'int8', 'unit_sales':'float32'}\n",
    "\n",
    "# Test period 07-26 to 08-10\n",
    "# train 35328\n",
    "train = pd.read_csv('../../input/train_small.csv',  dtype=dtypes, parse_dates=['date'])\n",
    "items = pd.read_csv('../../input/items.csv'  )\n",
    "logger.info('load data successful')\n",
    "\n",
    "#train_all.loc[(train_all.onpromotion!='True'),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35841 entries, 0 to 35840\n",
      "Data columns (total 5 columns):\n",
      "date           35841 non-null datetime64[ns]\n",
      "store_nbr      35841 non-null int8\n",
      "item_nbr       35841 non-null int32\n",
      "unit_sales     35841 non-null float32\n",
      "onpromotion    26874 non-null object\n",
      "dtypes: datetime64[ns](1), float32(1), int32(1), int8(1), object(1)\n",
      "memory usage: 875.1+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data processed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>unit_sales</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>DOW</th>\n",
       "      <th>WOY</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  store_nbr  item_nbr  unit_sales onpromotion  DOW  WOY  Year  \\\n",
       "0 2013-01-02          9    103501        19.0         NaN    2    1  2013   \n",
       "\n",
       "   Month  Day  \n",
       "0      1    2  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#train['unit_sales'] =  train['unit_sales'].apply(pd.np.log1p) #logarithm conversion\n",
    "\n",
    "train.loc[(train.unit_sales<0),'unit_sales'] = 0 # eliminate negatives\n",
    "train.loc[:, 'unit_sales'].fillna(0, inplace=True) # fill NaNs\n",
    "\n",
    "train['DOW'] = train['date'].dt.dayofweek\n",
    "train['WOY'] = train['date'].dt.weekofyear\n",
    "train['Year'] = train['date'].dt.year\n",
    "train['Month'] = train['date'].dt.month\n",
    "train['Day'] = train['date'].dt.day\n",
    "\n",
    "print('training data processed')\n",
    "\n",
    "train.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>unit_sales</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>DOW</th>\n",
       "      <th>WOY</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35718</th>\n",
       "      <td>2017-08-10</td>\n",
       "      <td>43</td>\n",
       "      <td>103501</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  store_nbr  item_nbr  unit_sales onpromotion  DOW  WOY  Year  \\\n",
       "35718 2017-08-10         43    103501        10.0       False    3   32  2017   \n",
       "\n",
       "       Month  Day  \n",
       "35718      8   10  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_all = train\n",
    "\n",
    "train = train_all.loc[(train_all.date <= '2017-07-25'), ]\n",
    "\n",
    "valid = train_all.loc[(train_all.date > '2017-07-25') & (train_all.date <= '2017-08-10' ), ]\n",
    "\n",
    "\n",
    "#train = train.loc[(train.store_nbr == 9), ]\n",
    "#test = test.loc[(test.store_nbr == 9), ]\n",
    "\n",
    "valid.tail(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DOW', 'WOY', 'unit_sales']\n",
      "training data processed\n",
      "Train a XGBoost model\n"
     ]
    }
   ],
   "source": [
    "#features = (['DOW', 'Month', 'Day', 'Year', 'WOY','unit_sales'])\n",
    "features = (['DOW', 'WOY','unit_sales'])\n",
    "print(features)\n",
    "\n",
    "print('training data processed')\n",
    "\n",
    "params = {\"objective\": \"reg:linear\",\n",
    "          \"booster\" : \"gbtree\",\n",
    "          \"eta\": 0.3,\n",
    "          \"max_depth\": 10,\n",
    "          \"subsample\": 0.9,\n",
    "          \"colsample_bytree\": 0.7,\n",
    "          \"silent\": 1,\n",
    "          \"seed\": 1301\n",
    "          }\n",
    "num_boost_round = 300\n",
    "\n",
    "print(\"Train a XGBoost model\")\n",
    "X_train, X_valid = train_test_split(train, test_size=0.012, random_state=10)\n",
    "y_train = np.log1p(X_train.unit_sales)\n",
    "y_valid = np.log1p(X_valid.unit_sales)\n",
    "dtrain = xgb.DMatrix(X_train[features], y_train)\n",
    "dvalid = xgb.DMatrix(X_valid[features], y_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35327, 10)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:0.842225\teval-rmse:0.862482\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 100 rounds.\n",
      "[1]\ttrain-rmse:0.647974\teval-rmse:0.665377\n",
      "[2]\ttrain-rmse:0.526309\teval-rmse:0.540369\n",
      "[3]\ttrain-rmse:0.370388\teval-rmse:0.379089\n",
      "[4]\ttrain-rmse:0.261896\teval-rmse:0.266882\n",
      "[5]\ttrain-rmse:0.184408\teval-rmse:0.187768\n",
      "[6]\ttrain-rmse:0.130449\teval-rmse:0.132593\n",
      "[7]\ttrain-rmse:0.093986\teval-rmse:0.094654\n",
      "[8]\ttrain-rmse:0.067839\teval-rmse:0.067835\n",
      "[9]\ttrain-rmse:0.05951\teval-rmse:0.059354\n",
      "[10]\ttrain-rmse:0.043969\teval-rmse:0.043453\n",
      "[11]\ttrain-rmse:0.033821\teval-rmse:0.032875\n",
      "[12]\ttrain-rmse:0.026908\teval-rmse:0.025899\n",
      "[13]\ttrain-rmse:0.024099\teval-rmse:0.023372\n",
      "[14]\ttrain-rmse:0.02259\teval-rmse:0.021983\n",
      "[15]\ttrain-rmse:0.018376\teval-rmse:0.017608\n",
      "[16]\ttrain-rmse:0.015563\teval-rmse:0.014917\n",
      "[17]\ttrain-rmse:0.014507\teval-rmse:0.013955\n",
      "[18]\ttrain-rmse:0.012741\teval-rmse:0.012431\n",
      "[19]\ttrain-rmse:0.01175\teval-rmse:0.011618\n",
      "[20]\ttrain-rmse:0.010908\teval-rmse:0.010868\n",
      "[21]\ttrain-rmse:0.010293\teval-rmse:0.010378\n",
      "[22]\ttrain-rmse:0.009962\teval-rmse:0.010131\n",
      "[23]\ttrain-rmse:0.008319\teval-rmse:0.008555\n",
      "[24]\ttrain-rmse:0.007731\teval-rmse:0.007811\n",
      "[25]\ttrain-rmse:0.007248\teval-rmse:0.007305\n",
      "[26]\ttrain-rmse:0.006177\teval-rmse:0.006392\n",
      "[27]\ttrain-rmse:0.005733\teval-rmse:0.005876\n",
      "[28]\ttrain-rmse:0.005478\teval-rmse:0.005625\n",
      "[29]\ttrain-rmse:0.004774\teval-rmse:0.004904\n",
      "[30]\ttrain-rmse:0.004578\teval-rmse:0.004668\n",
      "[31]\ttrain-rmse:0.00403\teval-rmse:0.004168\n",
      "[32]\ttrain-rmse:0.003859\teval-rmse:0.004026\n",
      "[33]\ttrain-rmse:0.003762\teval-rmse:0.003947\n",
      "[34]\ttrain-rmse:0.003684\teval-rmse:0.003859\n",
      "[35]\ttrain-rmse:0.003351\teval-rmse:0.003521\n",
      "[36]\ttrain-rmse:0.003271\teval-rmse:0.003461\n",
      "[37]\ttrain-rmse:0.003206\teval-rmse:0.003409\n",
      "[38]\ttrain-rmse:0.003165\teval-rmse:0.00336\n",
      "[39]\ttrain-rmse:0.002858\teval-rmse:0.003084\n",
      "[40]\ttrain-rmse:0.002822\teval-rmse:0.003065\n",
      "[41]\ttrain-rmse:0.002793\teval-rmse:0.003046\n",
      "[42]\ttrain-rmse:0.002753\teval-rmse:0.003007\n",
      "[43]\ttrain-rmse:0.002412\teval-rmse:0.00276\n",
      "[44]\ttrain-rmse:0.002272\teval-rmse:0.002625\n",
      "[45]\ttrain-rmse:0.002243\teval-rmse:0.002601\n",
      "[46]\ttrain-rmse:0.002227\teval-rmse:0.002593\n",
      "[47]\ttrain-rmse:0.002205\teval-rmse:0.002578\n",
      "[48]\ttrain-rmse:0.002074\teval-rmse:0.002464\n",
      "[49]\ttrain-rmse:0.002015\teval-rmse:0.002415\n",
      "[50]\ttrain-rmse:0.001971\teval-rmse:0.002378\n",
      "[51]\ttrain-rmse:0.001864\teval-rmse:0.00229\n",
      "[52]\ttrain-rmse:0.001853\teval-rmse:0.002267\n",
      "[53]\ttrain-rmse:0.001654\teval-rmse:0.002135\n",
      "[54]\ttrain-rmse:0.001618\teval-rmse:0.002123\n",
      "[55]\ttrain-rmse:0.001592\teval-rmse:0.002131\n",
      "[56]\ttrain-rmse:0.001581\teval-rmse:0.002113\n",
      "[57]\ttrain-rmse:0.001439\teval-rmse:0.002001\n",
      "[58]\ttrain-rmse:0.001378\teval-rmse:0.001973\n",
      "[59]\ttrain-rmse:0.001203\teval-rmse:0.00186\n",
      "[60]\ttrain-rmse:0.001187\teval-rmse:0.001858\n",
      "[61]\ttrain-rmse:0.001179\teval-rmse:0.001841\n",
      "[62]\ttrain-rmse:0.001175\teval-rmse:0.001824\n",
      "[63]\ttrain-rmse:0.001082\teval-rmse:0.001766\n",
      "[64]\ttrain-rmse:0.001055\teval-rmse:0.001744\n",
      "[65]\ttrain-rmse:0.001037\teval-rmse:0.001744\n",
      "[66]\ttrain-rmse:0.000933\teval-rmse:0.001692\n",
      "[67]\ttrain-rmse:0.000928\teval-rmse:0.001689\n",
      "[68]\ttrain-rmse:0.000911\teval-rmse:0.001672\n",
      "[69]\ttrain-rmse:0.000886\teval-rmse:0.001675\n",
      "[70]\ttrain-rmse:0.000883\teval-rmse:0.001663\n",
      "[71]\ttrain-rmse:0.000831\teval-rmse:0.001637\n",
      "[72]\ttrain-rmse:0.000829\teval-rmse:0.001637\n",
      "[73]\ttrain-rmse:0.000815\teval-rmse:0.001633\n",
      "[74]\ttrain-rmse:0.000813\teval-rmse:0.00163\n",
      "[75]\ttrain-rmse:0.000813\teval-rmse:0.00163\n",
      "[76]\ttrain-rmse:0.000813\teval-rmse:0.00163\n",
      "[77]\ttrain-rmse:0.000813\teval-rmse:0.001634\n",
      "[78]\ttrain-rmse:0.000703\teval-rmse:0.001583\n",
      "[79]\ttrain-rmse:0.000686\teval-rmse:0.001579\n",
      "[80]\ttrain-rmse:0.000684\teval-rmse:0.001578\n",
      "[81]\ttrain-rmse:0.000684\teval-rmse:0.001578\n",
      "[82]\ttrain-rmse:0.000684\teval-rmse:0.001571\n",
      "[83]\ttrain-rmse:0.000684\teval-rmse:0.001571\n",
      "[84]\ttrain-rmse:0.000683\teval-rmse:0.001561\n",
      "[85]\ttrain-rmse:0.000683\teval-rmse:0.001566\n",
      "[86]\ttrain-rmse:0.000683\teval-rmse:0.001566\n",
      "[87]\ttrain-rmse:0.000683\teval-rmse:0.001566\n",
      "[88]\ttrain-rmse:0.000683\teval-rmse:0.001566\n",
      "[89]\ttrain-rmse:0.000683\teval-rmse:0.001566\n",
      "[90]\ttrain-rmse:0.000683\teval-rmse:0.001566\n",
      "[91]\ttrain-rmse:0.000683\teval-rmse:0.001566\n",
      "[92]\ttrain-rmse:0.000683\teval-rmse:0.001566\n",
      "[93]\ttrain-rmse:0.000683\teval-rmse:0.001566\n",
      "[94]\ttrain-rmse:0.000682\teval-rmse:0.001569\n",
      "[95]\ttrain-rmse:0.000682\teval-rmse:0.001569\n",
      "[96]\ttrain-rmse:0.000681\teval-rmse:0.001571\n",
      "[97]\ttrain-rmse:0.000681\teval-rmse:0.001571\n",
      "[98]\ttrain-rmse:0.000681\teval-rmse:0.001571\n",
      "[99]\ttrain-rmse:0.000681\teval-rmse:0.001571\n",
      "[100]\ttrain-rmse:0.000681\teval-rmse:0.001571\n",
      "[101]\ttrain-rmse:0.000681\teval-rmse:0.001571\n",
      "[102]\ttrain-rmse:0.000681\teval-rmse:0.001571\n",
      "[103]\ttrain-rmse:0.000681\teval-rmse:0.001571\n",
      "[104]\ttrain-rmse:0.000681\teval-rmse:0.001571\n",
      "[105]\ttrain-rmse:0.00068\teval-rmse:0.001573\n",
      "[106]\ttrain-rmse:0.00068\teval-rmse:0.001573\n",
      "[107]\ttrain-rmse:0.00068\teval-rmse:0.001569\n",
      "[108]\ttrain-rmse:0.00068\teval-rmse:0.001569\n",
      "[109]\ttrain-rmse:0.00068\teval-rmse:0.001574\n",
      "[110]\ttrain-rmse:0.00068\teval-rmse:0.001574\n",
      "[111]\ttrain-rmse:0.00068\teval-rmse:0.001574\n",
      "[112]\ttrain-rmse:0.00068\teval-rmse:0.001574\n",
      "[113]\ttrain-rmse:0.00068\teval-rmse:0.001574\n",
      "[114]\ttrain-rmse:0.00068\teval-rmse:0.001574\n",
      "[115]\ttrain-rmse:0.000674\teval-rmse:0.001571\n",
      "[116]\ttrain-rmse:0.000674\teval-rmse:0.001571\n",
      "[117]\ttrain-rmse:0.000673\teval-rmse:0.001591\n",
      "[118]\ttrain-rmse:0.000673\teval-rmse:0.001591\n",
      "[119]\ttrain-rmse:0.000673\teval-rmse:0.001591\n",
      "[120]\ttrain-rmse:0.000672\teval-rmse:0.00158\n",
      "[121]\ttrain-rmse:0.000672\teval-rmse:0.00158\n",
      "[122]\ttrain-rmse:0.000672\teval-rmse:0.00158\n",
      "[123]\ttrain-rmse:0.000672\teval-rmse:0.00158\n",
      "[124]\ttrain-rmse:0.000672\teval-rmse:0.00158\n",
      "[125]\ttrain-rmse:0.000672\teval-rmse:0.00158\n",
      "[126]\ttrain-rmse:0.000672\teval-rmse:0.00158\n",
      "[127]\ttrain-rmse:0.000672\teval-rmse:0.00158\n",
      "[128]\ttrain-rmse:0.000672\teval-rmse:0.00158\n",
      "[129]\ttrain-rmse:0.000672\teval-rmse:0.00158\n",
      "[130]\ttrain-rmse:0.000672\teval-rmse:0.00158\n",
      "[131]\ttrain-rmse:0.000672\teval-rmse:0.001583\n",
      "[132]\ttrain-rmse:0.000672\teval-rmse:0.001583\n",
      "[133]\ttrain-rmse:0.000672\teval-rmse:0.001583\n",
      "[134]\ttrain-rmse:0.000672\teval-rmse:0.001583\n",
      "[135]\ttrain-rmse:0.000672\teval-rmse:0.00158\n",
      "[136]\ttrain-rmse:0.000672\teval-rmse:0.00158\n",
      "[137]\ttrain-rmse:0.000672\teval-rmse:0.00158\n",
      "[138]\ttrain-rmse:0.000672\teval-rmse:0.00158\n",
      "[139]\ttrain-rmse:0.000672\teval-rmse:0.00158\n",
      "[140]\ttrain-rmse:0.000672\teval-rmse:0.00158\n",
      "[141]\ttrain-rmse:0.000672\teval-rmse:0.00158\n",
      "[142]\ttrain-rmse:0.000672\teval-rmse:0.001579\n",
      "[143]\ttrain-rmse:0.000672\teval-rmse:0.001579\n",
      "[144]\ttrain-rmse:0.000672\teval-rmse:0.001579\n",
      "[145]\ttrain-rmse:0.000672\teval-rmse:0.001579\n",
      "[146]\ttrain-rmse:0.000672\teval-rmse:0.001579\n",
      "[147]\ttrain-rmse:0.000672\teval-rmse:0.001579\n",
      "[148]\ttrain-rmse:0.000672\teval-rmse:0.001579\n",
      "[149]\ttrain-rmse:0.000672\teval-rmse:0.001579\n",
      "[150]\ttrain-rmse:0.000672\teval-rmse:0.001579\n",
      "[151]\ttrain-rmse:0.000672\teval-rmse:0.001579\n",
      "[152]\ttrain-rmse:0.000672\teval-rmse:0.001579\n",
      "[153]\ttrain-rmse:0.000672\teval-rmse:0.001579\n",
      "[154]\ttrain-rmse:0.000672\teval-rmse:0.001579\n",
      "[155]\ttrain-rmse:0.000672\teval-rmse:0.001579\n",
      "[156]\ttrain-rmse:0.000672\teval-rmse:0.001579\n",
      "[157]\ttrain-rmse:0.000672\teval-rmse:0.001579\n",
      "[158]\ttrain-rmse:0.000672\teval-rmse:0.001579\n",
      "[159]\ttrain-rmse:0.000672\teval-rmse:0.001579\n",
      "[160]\ttrain-rmse:0.000672\teval-rmse:0.001579\n",
      "[161]\ttrain-rmse:0.000667\teval-rmse:0.001584\n",
      "[162]\ttrain-rmse:0.000667\teval-rmse:0.001584\n",
      "[163]\ttrain-rmse:0.000667\teval-rmse:0.001584\n",
      "[164]\ttrain-rmse:0.000667\teval-rmse:0.001584\n",
      "[165]\ttrain-rmse:0.000667\teval-rmse:0.001584\n",
      "[166]\ttrain-rmse:0.000667\teval-rmse:0.001584\n",
      "[167]\ttrain-rmse:0.000667\teval-rmse:0.001584\n",
      "[168]\ttrain-rmse:0.000667\teval-rmse:0.001584\n",
      "[169]\ttrain-rmse:0.000667\teval-rmse:0.001584\n",
      "[170]\ttrain-rmse:0.000667\teval-rmse:0.001583\n",
      "[171]\ttrain-rmse:0.000564\teval-rmse:0.001548\n",
      "[172]\ttrain-rmse:0.000563\teval-rmse:0.001547\n",
      "[173]\ttrain-rmse:0.000563\teval-rmse:0.001547\n",
      "[174]\ttrain-rmse:0.000563\teval-rmse:0.001547\n",
      "[175]\ttrain-rmse:0.000563\teval-rmse:0.001547\n",
      "[176]\ttrain-rmse:0.000563\teval-rmse:0.001547\n",
      "[177]\ttrain-rmse:0.000555\teval-rmse:0.001544\n",
      "[178]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[179]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[180]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[181]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[182]\ttrain-rmse:0.000552\teval-rmse:0.001549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[183]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[184]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[185]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[186]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[187]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[188]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[189]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[190]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[191]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[192]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[193]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[194]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[195]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[196]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[197]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[198]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[199]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[200]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[201]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[202]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[203]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[204]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[205]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[206]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[207]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[208]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[209]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[210]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[211]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[212]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[213]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[214]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[215]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[216]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[217]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[218]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[219]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[220]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[221]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[222]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[223]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[224]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[225]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[226]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[227]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[228]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[229]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[230]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[231]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[232]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[233]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[234]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[235]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[236]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[237]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[238]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[239]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[240]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[241]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[242]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[243]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[244]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[245]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[246]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[247]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[248]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[249]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[250]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[251]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[252]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[253]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[254]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[255]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[256]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[257]\ttrain-rmse:0.000552\teval-rmse:0.001549\n",
      "[258]\ttrain-rmse:0.000551\teval-rmse:0.001545\n",
      "[259]\ttrain-rmse:0.000551\teval-rmse:0.001545\n",
      "[260]\ttrain-rmse:0.000551\teval-rmse:0.001543\n",
      "[261]\ttrain-rmse:0.000551\teval-rmse:0.001555\n",
      "[262]\ttrain-rmse:0.000551\teval-rmse:0.001555\n",
      "[263]\ttrain-rmse:0.000551\teval-rmse:0.001555\n",
      "[264]\ttrain-rmse:0.000551\teval-rmse:0.001555\n",
      "[265]\ttrain-rmse:0.000551\teval-rmse:0.001555\n",
      "[266]\ttrain-rmse:0.000551\teval-rmse:0.001555\n",
      "[267]\ttrain-rmse:0.000551\teval-rmse:0.001555\n",
      "[268]\ttrain-rmse:0.000551\teval-rmse:0.001555\n",
      "[269]\ttrain-rmse:0.000551\teval-rmse:0.001555\n",
      "[270]\ttrain-rmse:0.000551\teval-rmse:0.001555\n",
      "[271]\ttrain-rmse:0.000551\teval-rmse:0.001555\n",
      "[272]\ttrain-rmse:0.000551\teval-rmse:0.001555\n",
      "[273]\ttrain-rmse:0.000551\teval-rmse:0.001555\n",
      "[274]\ttrain-rmse:0.000551\teval-rmse:0.001555\n",
      "[275]\ttrain-rmse:0.000551\teval-rmse:0.001555\n",
      "[276]\ttrain-rmse:0.000551\teval-rmse:0.001555\n",
      "[277]\ttrain-rmse:0.000551\teval-rmse:0.001555\n",
      "[278]\ttrain-rmse:0.000551\teval-rmse:0.001555\n",
      "[279]\ttrain-rmse:0.000551\teval-rmse:0.001555\n",
      "[280]\ttrain-rmse:0.000551\teval-rmse:0.001555\n",
      "[281]\ttrain-rmse:0.000551\teval-rmse:0.001555\n",
      "[282]\ttrain-rmse:0.000551\teval-rmse:0.001555\n",
      "[283]\ttrain-rmse:0.000551\teval-rmse:0.001555\n",
      "[284]\ttrain-rmse:0.000551\teval-rmse:0.001555\n",
      "[285]\ttrain-rmse:0.000551\teval-rmse:0.001555\n",
      "[286]\ttrain-rmse:0.000551\teval-rmse:0.001555\n",
      "[287]\ttrain-rmse:0.000551\teval-rmse:0.001555\n",
      "[288]\ttrain-rmse:0.000551\teval-rmse:0.001555\n",
      "[289]\ttrain-rmse:0.000551\teval-rmse:0.001555\n",
      "[290]\ttrain-rmse:0.000551\teval-rmse:0.001555\n",
      "[291]\ttrain-rmse:0.000551\teval-rmse:0.001555\n",
      "[292]\ttrain-rmse:0.000551\teval-rmse:0.001555\n",
      "[293]\ttrain-rmse:0.000551\teval-rmse:0.001555\n",
      "[294]\ttrain-rmse:0.000551\teval-rmse:0.001555\n",
      "[295]\ttrain-rmse:0.000551\teval-rmse:0.001555\n",
      "[296]\ttrain-rmse:0.000551\teval-rmse:0.001555\n",
      "[297]\ttrain-rmse:0.000551\teval-rmse:0.001555\n",
      "[298]\ttrain-rmse:0.000551\teval-rmse:0.001556\n",
      "[299]\ttrain-rmse:0.000551\teval-rmse:0.001556\n"
     ]
    }
   ],
   "source": [
    "\n",
    "watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "gbm = xgb.train(params, dtrain, num_boost_round, evals=watchlist, \\\n",
    "  early_stopping_rounds=100, verbose_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DOW': 1948, 'WOY': 5537, 'unit_sales': 3086}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_feature_map(features)\n",
    "importance = gbm.get_fscore(fmap='xgb.fmap')\n",
    "importance\n",
    "#importance = sorted(importance.items(), key=operator.itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating\n"
     ]
    }
   ],
   "source": [
    "print(\"Validating\")\n",
    "test = valid\n",
    "test['pred_sales'] = gbm.predict(xgb.DMatrix(test[features]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>unit_sales</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>DOW</th>\n",
       "      <th>WOY</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>pred_sales</th>\n",
       "      <th>family</th>\n",
       "      <th>class</th>\n",
       "      <th>perishable</th>\n",
       "      <th>weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-07-26</td>\n",
       "      <td>9</td>\n",
       "      <td>103501</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "      <td>1.386789</td>\n",
       "      <td>CLEANING</td>\n",
       "      <td>3008</td>\n",
       "      <td>0</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-07-26</td>\n",
       "      <td>11</td>\n",
       "      <td>103501</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "      <td>0.693758</td>\n",
       "      <td>CLEANING</td>\n",
       "      <td>3008</td>\n",
       "      <td>0</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  store_nbr  item_nbr  unit_sales onpromotion  DOW  WOY  Year  \\\n",
       "0 2017-07-26          9    103501         3.0       False    2   30  2017   \n",
       "1 2017-07-26         11    103501         1.0       False    2   30  2017   \n",
       "\n",
       "   Month  Day  pred_sales    family  class  perishable  weights  \n",
       "0      7   26    1.386789  CLEANING   3008           0     1.25  \n",
       "1      7   26    0.693758  CLEANING   3008           0     1.25  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_e = pd.merge(test, items, on='item_nbr',how='inner')\n",
    "test_e['weights'] = 1\n",
    "test_e.loc[(test_e.perishable== 0), ('weights')] = 1.25\n",
    "test_e.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecast Period From: 2017-07-26 00:00:00  To:  2017-08-10 00:00:00\n",
      "NWRMSLE_A =  0.6973722969698247\n"
     ]
    }
   ],
   "source": [
    "#print(test.loc[:, \"unit_sales\"].isnull().values.any())\n",
    "#print(test.loc[:, \"pred_sales\"].isnull().values.any())\n",
    "weights = np.ones(test_e.shape[0])\n",
    "result = NWRMSLE_A(test_e.unit_sales,test_e.pred_sales, test_e.weights)\n",
    "print(\"Forecast Period From:\", min(test.date),\" To: \", max(test.date))\n",
    "print(\"NWRMSLE_A = \",result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in test is 147\n",
      "Forecast Period From: 2017-07-26 00:00:00  To:  2017-07-31 00:00:00\n",
      "NWRMSLE =  0.7215935018713918\n"
     ]
    }
   ],
   "source": [
    "#### check result on first 6 days.\n",
    "test_p1 = test_e.loc[(test_e.date < '2017-08-01'), ]\n",
    "weights_p1 = np.ones(test_p1.shape[0])\n",
    "result_p1 = NWRMSLE_A(test_p1.unit_sales.astype(np.float32),test_p1.pred_sales.astype(np.float32), test_p1.weights)\n",
    "print(\"Number of rows in test is\", test_p1.shape[0])\n",
    "print(\"Forecast Period From:\", min(test_p1.date),\" To: \", max(test_p1.date))\n",
    "print(\"NWRMSLE = \",result_p1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
