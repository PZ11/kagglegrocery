{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-01-04 20:42:49,548 __main__ 40 [INFO][<module>] start \n",
      "2018-01-04 20:42:49,548 __main__ 40 [INFO][<module>] start \n",
      "2018-01-04 20:42:49,548 __main__ 40 [INFO][<module>] start \n",
      "/home/zyp/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "This is an upgraded version of Ceshine's LGBM starter script, simply adding\n",
    "more average features and weekly average features on it.\n",
    "\"\"\"\n",
    "from datetime import date, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import sys\n",
    "import math\n",
    "import gc\n",
    "import sklearn.metrics as skl_metrics\n",
    "\n",
    "# import math\n",
    "# import sklearn.metrics as skl_metrics\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from logging import StreamHandler, DEBUG, Formatter, FileHandler, getLogger\n",
    "\n",
    "logger = getLogger(__name__)\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "DIR = '../logs/'\n",
    "\n",
    "log_fmt = Formatter('%(asctime)s %(name)s %(lineno)d [%(levelname)s]\\\n",
    "[%(funcName)s] %(message)s ')\n",
    "handler = StreamHandler()\n",
    "handler.setLevel('INFO')\n",
    "handler.setFormatter(log_fmt)\n",
    "logger.addHandler(handler)\n",
    "\n",
    "handler = FileHandler(DIR + 'train.py.log', 'a')\n",
    "handler.setLevel(DEBUG)\n",
    "handler.setFormatter(log_fmt)\n",
    "logger.setLevel(DEBUG)\n",
    "logger.addHandler(handler)\n",
    "\n",
    "logger.info('start')\n",
    "\n",
    "\n",
    "df_train = pd.read_csv(\n",
    "    '../input/train_2s.csv', usecols=[1, 2, 3, 4, 5],\n",
    "    dtype={'onpromotion': bool},\n",
    "    converters={'unit_sales': lambda u: np.log1p(\n",
    "        float(u)) if float(u) > 0 else 0},\n",
    "    parse_dates=[\"date\"],\n",
    ")\n",
    "\n",
    "df_test = pd.read_csv(\n",
    "    \"../input/test_2s.csv\", usecols=[0, 1, 2, 3, 4],\n",
    "    dtype={'onpromotion': bool},\n",
    "    parse_dates=[\"date\"]  # , date_parser=parser\n",
    ").set_index(\n",
    "    ['store_nbr', 'item_nbr', 'date']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>class</th>\n",
       "      <th>perishable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>96995</td>\n",
       "      <td>GROCERY I</td>\n",
       "      <td>1093</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_nbr     family  class  perishable\n",
       "0     96995  GROCERY I   1093           0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = pd.read_csv(\"../input/items.csv\",)\n",
    "items.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_timespan(df, dt, minus, periods, freq='D'):\n",
    "    return df[pd.date_range\n",
    "              (dt - timedelta(days=minus), periods=periods, freq=freq)]\n",
    "\n",
    "\n",
    "\n",
    "def prepare_dataset(t2017, is_train=True):\n",
    "    X = pd.DataFrame({\n",
    "        \"family\": df_2017_nbr.family,\n",
    "        \"date\": (t2017), \n",
    "        \"s_f_day_1_2017\": get_timespan(df_2017, t2017, 1, 1).values.ravel(),\n",
    "        \"s_f_mean_7_2017\": get_timespan(df_2017, t2017, 7, 7).mean(axis=1).values,\n",
    "        \"s_f_mean_21_2017\": get_timespan(df_2017, t2017, 21, 21).mean(axis=1).values,\n",
    "        \"s_f_mean_42_2017\": get_timespan(df_2017, t2017, 42, 42).mean(axis=1).values,\n",
    "        \"s_f_mean_91_2017\": get_timespan(df_2017, t2017, 91, 91).mean(axis=1).values,\n",
    "        \"s_f_mean_182_2017\": get_timespan(df_2017, t2017, 182, 182).mean(axis=1).values,\n",
    "        \"s_f_mean_364_2017\": get_timespan(df_2017, t2017, 364, 364).mean(axis=1).values,\n",
    "    })\n",
    "  \n",
    "    for i in range(7):\n",
    "        X['s_f_dow_4_{}_mean'.format(i)] = get_timespan(df_2017, t2017, 28-i, 4, freq='7D').mean(axis=1).values\n",
    "        X['s_f_dow_13_{}_mean'.format(i)] = get_timespan(df_2017, t2017, 91-i, 13, freq='7D').mean(axis=1).values\n",
    "        X['s_f_dow_26_{}_mean'.format(i)] = get_timespan(df_2017, t2017, 182-i, 26, freq='7D').mean(axis=1).values\n",
    "        X['s_f_dow_52_{}_mean'.format(i)] = get_timespan(df_2017, t2017, 364-i, 52, freq='7D').mean(axis=1).values        \n",
    "\n",
    "\n",
    "    if is_train:\n",
    "        y = df_2017[\n",
    "            pd.date_range(t2017, periods=16)\n",
    "        ].values\n",
    "        return X, y\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_store_items = pd.merge(df_train, items, on =['item_nbr'], how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>unit_sales</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>family</th>\n",
       "      <th>class</th>\n",
       "      <th>perishable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>103665</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BREAD/BAKERY</td>\n",
       "      <td>2712</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  store_nbr  item_nbr  unit_sales onpromotion        family  \\\n",
       "0 2013-01-01         25    103665    2.079442         NaN  BREAD/BAKERY   \n",
       "\n",
       "   class  perishable  \n",
       "0   2712           1  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_store_items.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Aggregate to item level\n",
    "df_train_store_family = df_train_store_items[['family','date', 'store_nbr', 'unit_sales']].groupby(['family','date'])\\\n",
    "    .agg({'unit_sales': 'sum', 'store_nbr':'count'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df_train_store_family[\"item_avg_sales\"] = df_train_store_family[\"unit_sales\"] / df_train_store_family[\"store_nbr\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_2017 = df_train_store_family.set_index(\n",
    "    [\"family\", \"store_nbr\", \"date\"])[[\"item_avg_sales\"]].unstack(\n",
    "        level=-1).fillna(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_2017.columns = df_2017.columns.get_level_values(1)\n",
    "\n",
    "df_2017_nbr = pd.DataFrame(df_2017.copy())\n",
    "df_2017_nbr.reset_index(inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>date</th>\n",
       "      <th>family</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>2013-01-01 00:00:00</th>\n",
       "      <th>2013-01-02 00:00:00</th>\n",
       "      <th>2013-01-03 00:00:00</th>\n",
       "      <th>2013-01-04 00:00:00</th>\n",
       "      <th>2013-01-05 00:00:00</th>\n",
       "      <th>2013-01-06 00:00:00</th>\n",
       "      <th>2013-01-07 00:00:00</th>\n",
       "      <th>2013-01-08 00:00:00</th>\n",
       "      <th>...</th>\n",
       "      <th>2017-08-06 00:00:00</th>\n",
       "      <th>2017-08-07 00:00:00</th>\n",
       "      <th>2017-08-08 00:00:00</th>\n",
       "      <th>2017-08-09 00:00:00</th>\n",
       "      <th>2017-08-10 00:00:00</th>\n",
       "      <th>2017-08-11 00:00:00</th>\n",
       "      <th>2017-08-12 00:00:00</th>\n",
       "      <th>2017-08-13 00:00:00</th>\n",
       "      <th>2017-08-14 00:00:00</th>\n",
       "      <th>2017-08-15 00:00:00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 1686 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "date      family  store_nbr  2013-01-01 00:00:00  2013-01-02 00:00:00  \\\n",
       "0     AUTOMOTIVE          1                  0.0                  0.0   \n",
       "\n",
       "date  2013-01-03 00:00:00  2013-01-04 00:00:00  2013-01-05 00:00:00  \\\n",
       "0                     0.0                  0.0                  0.0   \n",
       "\n",
       "date  2013-01-06 00:00:00  2013-01-07 00:00:00  2013-01-08 00:00:00  \\\n",
       "0                     0.0             0.693147                  0.0   \n",
       "\n",
       "date         ...           2017-08-06 00:00:00  2017-08-07 00:00:00  \\\n",
       "0            ...                           0.0                  0.0   \n",
       "\n",
       "date  2017-08-08 00:00:00  2017-08-09 00:00:00  2017-08-10 00:00:00  \\\n",
       "0                     0.0                  0.0                  0.0   \n",
       "\n",
       "date  2017-08-11 00:00:00  2017-08-12 00:00:00  2017-08-13 00:00:00  \\\n",
       "0                     0.0                  0.0                  0.0   \n",
       "\n",
       "date  2017-08-14 00:00:00  2017-08-15 00:00:00  \n",
       "0                0.693147                  0.0  \n",
       "\n",
       "[1 rows x 1686 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2017_nbr.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    \n",
    "df_2017[pd.datetime(2016, 12, 25)] = 0\n",
    "df_2017[pd.datetime(2015, 12, 25)] = 0\n",
    "df_2017[pd.datetime(2014, 12, 25)] = 0\n",
    "df_2017[pd.datetime(2017, 1, 1)] = 0\n",
    "df_2017[pd.datetime(2016, 1, 1)] = 0\n",
    "df_2017[pd.datetime(2015, 1, 1)] = 0    \n",
    "df_2017[pd.datetime(2015, 7, 7)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_1 = '1s'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-01-04 20:50:50,816 __main__ 2 [INFO][<module>] Preparing traing dataset... \n",
      "2018-01-04 20:50:50,816 __main__ 2 [INFO][<module>] Preparing traing dataset... \n",
      "2018-01-04 20:50:50,816 __main__ 2 [INFO][<module>] Preparing traing dataset... \n",
      "2018-01-04 20:50:52,065 __main__ 39 [INFO][<module>] Save Store Item Features ... \n",
      "2018-01-04 20:50:52,065 __main__ 39 [INFO][<module>] Save Store Item Features ... \n",
      "2018-01-04 20:50:52,065 __main__ 39 [INFO][<module>] Save Store Item Features ... \n"
     ]
    }
   ],
   "source": [
    "##########################################################################\n",
    "logger.info('Preparing traing dataset...')\n",
    "\n",
    "X_l, y_l = [], []\n",
    "\n",
    "t2016 = date(2016, 8, 3)\n",
    "for i in range(4):\n",
    "    delta = timedelta(days=7 * i)\n",
    "    X_tmp, y_tmp = prepare_dataset(\n",
    "        t2016 + delta\n",
    "    )\n",
    "    X_l.append(X_tmp)\n",
    "    y_l.append(y_tmp)\n",
    "\n",
    "train_week_2017 = 7\n",
    "if param_1 != \"val\":\n",
    "    train_week_2017 = 9\n",
    "\n",
    "t2017 = date(2017, 5, 31)\n",
    "for i in range(train_week_2017):\n",
    "    delta = timedelta(days=7 * i)\n",
    "    X_tmp, y_tmp = prepare_dataset(\n",
    "        t2017 + delta\n",
    "    )\n",
    "    X_l.append(X_tmp)\n",
    "    y_l.append(y_tmp)\n",
    "\n",
    "\n",
    "X_train = pd.concat(X_l, axis=0)\n",
    "y_train = np.concatenate(y_l, axis=0)\n",
    "del X_l, y_l\n",
    "\n",
    "delta = timedelta(0)\n",
    "\n",
    "X_val, y_val = prepare_dataset(date(2017, 7, 26))\n",
    "X_test = prepare_dataset(date(2017, 8, 16), is_train=False)\n",
    "\n",
    "##########################################################################\n",
    "logger.info('Save Store Item Features ...')\n",
    "\n",
    "y_columns = [\"day\" + str(i) for i in range(1, 17)]\n",
    "\n",
    "df_y_train = pd.DataFrame(data = y_train, columns = y_columns)\n",
    "X_train.reset_index(inplace = True)\n",
    "X_train.reindex(index = df_y_train.index)\n",
    "#train_out = pd.concat([X_train, df_y_train], axis = 1) \n",
    "train_out = X_train\n",
    "\n",
    "df_y_val = pd.DataFrame(data = y_val, columns = y_columns)\n",
    "X_val.reset_index(inplace = True)\n",
    "X_val.reindex(index = df_y_val.index)\n",
    "#val_out = pd.concat([X_val, df_y_val], axis = 1)\n",
    "val_out = X_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 36088 entries, 0 to 36087\n",
      "Data columns (total 38 columns):\n",
      "index                36088 non-null int64\n",
      "date                 36088 non-null object\n",
      "family               36088 non-null object\n",
      "s_f_day_1_2017       36088 non-null float64\n",
      "s_f_mean_182_2017    36088 non-null float64\n",
      "s_f_mean_21_2017     36088 non-null float64\n",
      "s_f_mean_364_2017    36088 non-null float64\n",
      "s_f_mean_42_2017     36088 non-null float64\n",
      "s_f_mean_7_2017      36088 non-null float64\n",
      "s_f_mean_91_2017     36088 non-null float64\n",
      "s_f_dow_4_0_mean     36088 non-null float64\n",
      "s_f_dow_13_0_mean    36088 non-null float64\n",
      "s_f_dow_26_0_mean    36088 non-null float64\n",
      "s_f_dow_52_0_mean    36088 non-null float64\n",
      "s_f_dow_4_1_mean     36088 non-null float64\n",
      "s_f_dow_13_1_mean    36088 non-null float64\n",
      "s_f_dow_26_1_mean    36088 non-null float64\n",
      "s_f_dow_52_1_mean    36088 non-null float64\n",
      "s_f_dow_4_2_mean     36088 non-null float64\n",
      "s_f_dow_13_2_mean    36088 non-null float64\n",
      "s_f_dow_26_2_mean    36088 non-null float64\n",
      "s_f_dow_52_2_mean    36088 non-null float64\n",
      "s_f_dow_4_3_mean     36088 non-null float64\n",
      "s_f_dow_13_3_mean    36088 non-null float64\n",
      "s_f_dow_26_3_mean    36088 non-null float64\n",
      "s_f_dow_52_3_mean    36088 non-null float64\n",
      "s_f_dow_4_4_mean     36088 non-null float64\n",
      "s_f_dow_13_4_mean    36088 non-null float64\n",
      "s_f_dow_26_4_mean    36088 non-null float64\n",
      "s_f_dow_52_4_mean    36088 non-null float64\n",
      "s_f_dow_4_5_mean     36088 non-null float64\n",
      "s_f_dow_13_5_mean    36088 non-null float64\n",
      "s_f_dow_26_5_mean    36088 non-null float64\n",
      "s_f_dow_52_5_mean    36088 non-null float64\n",
      "s_f_dow_4_6_mean     36088 non-null float64\n",
      "s_f_dow_13_6_mean    36088 non-null float64\n",
      "s_f_dow_26_6_mean    36088 non-null float64\n",
      "s_f_dow_52_6_mean    36088 non-null float64\n",
      "dtypes: float64(35), int64(1), object(2)\n",
      "memory usage: 10.5+ MB\n"
     ]
    }
   ],
   "source": [
    "train_out.info(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_f_train_out = pd.merge(train_out, items[['item_nbr','family']], how = 'inner' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'family'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2441\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2442\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2443\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'family'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-0e89c5fbc3a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0ms_f_train_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'family'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__delitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1899\u001b[0m             \u001b[0;31m# there was no match, this call should raise the appropriate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1900\u001b[0m             \u001b[0;31m# exception:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1901\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1902\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1903\u001b[0m         \u001b[0;31m# delete from the caches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mdelete\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   3647\u001b[0m         \u001b[0mDelete\u001b[0m \u001b[0mselected\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnon\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mplace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3648\u001b[0m         \"\"\"\n\u001b[0;32m-> 3649\u001b[0;31m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3651\u001b[0m         \u001b[0mis_deleted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2442\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2443\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2444\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2446\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'family'"
     ]
    }
   ],
   "source": [
    "del s_f_train_out['family']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
