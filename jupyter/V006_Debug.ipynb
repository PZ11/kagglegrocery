{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-01-02 11:01:02,485 __main__ 37 [INFO][<module>] start \n",
      "/home/zyp/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "2018-01-02 11:01:08,620 __main__ 168 [INFO][<module>] Preparing datasetn... \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "This is an upgraded version of Ceshine's LGBM starter script, simply adding more\n",
    "average features and weekly average features on it.\n",
    "\"\"\"\n",
    "from datetime import date, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "import sys\n",
    "\n",
    "import math\n",
    "import sklearn.metrics as skl_metrics\n",
    "\n",
    "from datetime import timedelta\n",
    "from logging import StreamHandler, DEBUG, Formatter, FileHandler, getLogger\n",
    "\n",
    "logger = getLogger(__name__)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "DIR = '../logs/'\n",
    "\n",
    "log_fmt = Formatter('%(asctime)s %(name)s %(lineno)d [%(levelname)s][%(funcName)s] %(message)s ')\n",
    "handler = StreamHandler()\n",
    "handler.setLevel('INFO')\n",
    "handler.setFormatter(log_fmt)\n",
    "logger.addHandler(handler)\n",
    "\n",
    "handler = FileHandler(DIR + 'train.py.log', 'a')\n",
    "handler.setLevel(DEBUG)\n",
    "handler.setFormatter(log_fmt)\n",
    "logger.setLevel(DEBUG)\n",
    "logger.addHandler(handler)\n",
    "\n",
    "logger.info('start')\n",
    "\n",
    "#------------------------------------------------------------------------------------#\n",
    "\n",
    "df_train = pd.read_csv(\n",
    "    '../input/train_1s.csv', usecols=[1, 2, 3, 4, 5],\n",
    "    dtype={'onpromotion': bool},\n",
    "    converters={'unit_sales': lambda u: np.log1p(\n",
    "    float(u)) if float(u) > 0 else 0},\n",
    "    parse_dates=[\"date\"],\n",
    ")\n",
    "\n",
    "df_test = pd.read_csv(\n",
    "    \"../input/test_1s.csv\", usecols=[0, 1, 2, 3, 4],\n",
    "    dtype={'onpromotion': bool},\n",
    "    parse_dates=[\"date\"]  # , date_parser=parser\n",
    ").set_index(\n",
    "    ['store_nbr', 'item_nbr', 'date']\n",
    ")\n",
    "\n",
    "\n",
    "items = pd.read_csv(\n",
    "    \"../input/items.csv\",\n",
    ").set_index(\"item_nbr\")\n",
    "\n",
    "df_2017 = df_train.loc[df_train.date>=pd.datetime(2017,1,1)]\n",
    "del df_train\n",
    "\n",
    "promo_2017_train = df_2017.set_index(\n",
    "    [\"store_nbr\", \"item_nbr\", \"date\"])[[\"onpromotion\"]].unstack(\n",
    "        level=-1).fillna(False)\n",
    "promo_2017_train.columns = promo_2017_train.columns.get_level_values(1)\n",
    "promo_2017_test = df_test[[\"onpromotion\"]].unstack(level=-1).fillna(False)\n",
    "promo_2017_test.columns = promo_2017_test.columns.get_level_values(1)\n",
    "promo_2017_test = promo_2017_test.reindex(promo_2017_train.index).fillna(False)\n",
    "promo_2017 = pd.concat([promo_2017_train, promo_2017_test], axis=1)\n",
    "del promo_2017_test, promo_2017_train\n",
    "\n",
    "df_2017 = df_2017.set_index(\n",
    "    [\"store_nbr\", \"item_nbr\", \"date\"])[[\"unit_sales\"]].unstack(\n",
    "        level=-1).fillna(0)\n",
    "df_2017.columns = df_2017.columns.get_level_values(1)\n",
    "\n",
    "items = items.reindex(df_2017.index.get_level_values(1))\n",
    "\n",
    "df_2017[pd.datetime(2017, 1, 1)] = 0\n",
    "df_2017[pd.datetime(2016, 12, 25)] = 0\n",
    "\n",
    "#------------------------------------------------------------------------------------------#\n",
    "# Functions\n",
    "\n",
    "def create_feature_map(features):\n",
    "    outfile = open('xgb.fmap', 'w')\n",
    "    for i, feat in enumerate(features):\n",
    "        outfile.write('{0}\\t{1}\\tq\\n'.format(i, feat))\n",
    "    outfile.close()\n",
    "\n",
    "def NWRMSLE(y, pred, weights=None):\n",
    "    err2 = skl_metrics.mean_squared_log_error(y, pred, sample_weight=weights)\n",
    "    return math.sqrt(err2)\n",
    "\n",
    "def get_timespan(df, dt, minus, periods, freq='D'):\n",
    "    return df[pd.date_range(dt - timedelta(days=minus), periods=periods, freq=freq)]\n",
    "\n",
    "def prepare_dataset(t2017, is_train=True):\n",
    "    X = pd.DataFrame({\n",
    "        \"day_1_2017\": get_timespan(df_2017, t2017, 1, 1).values.ravel(),\n",
    "        \"mean_3_2017\": get_timespan(df_2017, t2017, 3, 3).mean(axis=1).values,\n",
    "        \"mean_7_2017\": get_timespan(df_2017, t2017, 7, 7).mean(axis=1).values,\n",
    "        \"mean_14_2017\": get_timespan(df_2017, t2017, 14, 14).mean(axis=1).values,\n",
    "        #\"mean_30_2017\": get_timespan(df_2017, t2017, 30, 30).mean(axis=1).values,\n",
    "        #\"mean_60_2017\": get_timespan(df_2017, t2017, 60, 60).mean(axis=1).values,\n",
    "        #\"mean_140_2017\": get_timespan(df_2017, t2017, 140, 140).mean(axis=1).values,\n",
    "        \n",
    "        #\"mean_21_2017\": get_timespan(df_2017, t2017, 21, 21).mean(axis=1).values,\n",
    "        #\"mean_42_2017\": get_timespan(df_2017, t2017, 42, 42).mean(axis=1).values,\n",
    "        #\"mean_91_2017\": get_timespan(df_2017, t2017, 91, 91).mean(axis=1).values,\n",
    "        #\"mean_150_2017\": get_timespan(df_2017, t2017, 150, 150).mean(axis=1).values,\n",
    "        \n",
    "        #\"promo_14_2017\": get_timespan(promo_2017, t2017, 14, 14).sum(axis=1).values,\n",
    "        #\"promo_60_2017\": get_timespan(promo_2017, t2017, 60, 60).sum(axis=1).values,\n",
    "        #\"promo_140_2017\": get_timespan(promo_2017, t2017, 140, 140).sum(axis=1).values\n",
    "    })\n",
    "    for i in range(7):\n",
    "        X['mean_4_dow{}_2017'.format(i)] = get_timespan(df_2017, t2017, 28-i, 4, freq='7D').mean(axis=1).values\n",
    "        X['mean_20_dow{}_2017'.format(i)] = get_timespan(df_2017, t2017, 140-i, 20, freq='7D').mean(axis=1).values\n",
    "    for i in range(16):\n",
    "        X[\"promo_{}\".format(i)] = promo_2017[\n",
    "            t2017 + timedelta(days=i)].values.astype(np.uint8)\n",
    "    if is_train:\n",
    "        y = df_2017[\n",
    "            pd.date_range(t2017, periods=16)\n",
    "        ].values\n",
    "        return X, y\n",
    "    return X\n",
    "\n",
    "\n",
    "def eval_test(test_e):\n",
    "\n",
    "    test_e['weights'] = 1\n",
    "    test_e.loc[(test_e.perishable == 1), ('weights')] = 1.25\n",
    "\n",
    "    result = NWRMSLE(test_e.unit_sales.astype(np.float64),test_e.pred_sales.astype(np.float64), test_e.weights)\n",
    "\n",
    "    print(\"Eval All, Number of rows in test is\", test_e.shape[0])\n",
    "    print(\"Eval all, Forecast Period From:\", min(test_e.date),\" To: \", max(test_e.date))\n",
    "\n",
    "    #### check result on first 6 days.\n",
    "    test_p1 = test_e.loc[(test_e.date < '2017-08-01'), ]\n",
    "    result_p1 = NWRMSLE(test_p1.unit_sales.astype(np.float32),test_p1.pred_sales.astype(np.float32), test_p1.weights)\n",
    "\n",
    "    print(\"Eval P1, Number of rows in test is\", test_p1.shape[0])\n",
    "    print(\"Eval P1, Forecast Period From:\", min(test_p1.date),\" To: \", max(test_p1.date))\n",
    "\n",
    "    #### check result on last 10 days.\n",
    "    test_p2 = test_e.loc[(test_e.date >= '2017-08-01'), ]\n",
    "    result_p2 = NWRMSLE(test_p2.unit_sales.astype(np.float32),test_p2.pred_sales.astype(np.float32), test_p2.weights)\n",
    "\n",
    "    print(\"Eval P2, Number of rows in test is\", test_p2.shape[0])\n",
    "    print(\"Eval P2, Forecast Period From:\", min(test_p2.date),\" To: \", max(test_p2.date))\n",
    "\n",
    "    print(\"Eval All Weighted NWRMSLE = \",result)\n",
    "    print(\"Eval P1  Weighted NWRMSLE = \",result_p1)\n",
    "    print(\"Eval P2  Weighted NWRMSLE = \",result_p2)\n",
    "\n",
    "    \n",
    "    test_e['error'] =  abs(test_e.pred_sales - test_e.unit_sales)\n",
    "    print(\"Bias =\",  (test_e.pred_sales.sum() - test_e.unit_sales.sum()) /  test_e.unit_sales.sum())\n",
    "    print(\"WMAPE =\",  abs(test_e.error.sum() - test_e.unit_sales.sum()) /  test_e.unit_sales.sum())\n",
    "    \n",
    "#------------------------------------------------------------------------------------------#\n",
    "logger.info('Preparing datasetn...')\n",
    "\n",
    "t2017 = date(2017, 5, 31)\n",
    "X_l, y_l = [], []\n",
    "for i in range(6):\n",
    "    delta = timedelta(days=7 * i)\n",
    "    X_tmp, y_tmp = prepare_dataset(\n",
    "        t2017 + delta\n",
    "    )\n",
    "    X_l.append(X_tmp)\n",
    "    y_l.append(y_tmp)\n",
    "X_train_allF = pd.concat(X_l, axis=0)\n",
    "y_train = np.concatenate(y_l, axis=0)\n",
    "del X_l, y_l\n",
    "X_val_allF, y_val = prepare_dataset(date(2017, 7, 26))\n",
    "X_test = prepare_dataset(date(2017, 8, 16), is_train=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Step 16\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "features_all = X_train_allF.columns.tolist()\n",
    "i = 15\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"Step %d\" % (i+1))\n",
    "print(\"=\" * 50)\n",
    "\n",
    "features_t = features_all.copy()\n",
    "\n",
    "for j in range(16):\n",
    "    if j != i:\n",
    "        features_t.remove(\"promo_{}\".format(j))\n",
    "\n",
    "for j in range(7):\n",
    "    if j != i%7:\n",
    "        features_t.remove('mean_4_dow{}_2017'.format(j))\n",
    "        features_t.remove('mean_20_dow{}_2017'.format(j))\n",
    "        \n",
    "X_train = X_train_allF[features_t]\n",
    "X_val = X_val_allF[features_t]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 20754 entries, 0 to 3458\n",
      "Data columns (total 7 columns):\n",
      "day_1_2017           20754 non-null float64\n",
      "mean_14_2017         20754 non-null float64\n",
      "mean_3_2017          20754 non-null float64\n",
      "mean_7_2017          20754 non-null float64\n",
      "mean_4_dow1_2017     20754 non-null float64\n",
      "mean_20_dow1_2017    20754 non-null float64\n",
      "promo_15             20754 non-null uint8\n",
      "dtypes: float64(6), uint8(1)\n",
      "memory usage: 1.1 MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-01-02 11:01:08,983 __main__ 3 [INFO][<module>] Training and predicting models... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Step 1\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zyp/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1027: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[44]\ttraining's l2: 0.285433\tvalid_1's l2: 0.284064\n",
      "mean_7_2017: 32992.22\n",
      "mean_14_2017: 21698.02\n",
      "mean_20_dow0_2017: 6910.73\n",
      "promo_0: 2657.10\n",
      "mean_3_2017: 1411.59\n",
      "mean_20_dow6_2017: 859.31\n",
      "mean_4_dow0_2017: 671.51\n",
      "day_1_2017: 561.85\n",
      "mean_4_dow6_2017: 487.25\n",
      "mean_4_dow5_2017: 386.60\n",
      "mean_4_dow2_2017: 280.50\n",
      "mean_20_dow5_2017: 270.05\n",
      "mean_20_dow1_2017: 214.10\n",
      "mean_4_dow1_2017: 194.33\n",
      "mean_4_dow3_2017: 187.49\n",
      "mean_20_dow2_2017: 143.05\n",
      "mean_20_dow4_2017: 120.69\n",
      "mean_4_dow4_2017: 94.70\n",
      "mean_20_dow3_2017: 81.85\n",
      "==================================================\n",
      "Step 2\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.27712\tvalid_1's l2: 0.306631\n",
      "Early stopping, best iteration is:\n",
      "[56]\ttraining's l2: 0.292833\tvalid_1's l2: 0.304865\n",
      "mean_7_2017: 20819.52\n",
      "mean_14_2017: 20593.56\n",
      "mean_20_dow1_2017: 6482.15\n",
      "mean_4_dow1_2017: 1290.83\n",
      "promo_1: 1125.96\n",
      "mean_20_dow0_2017: 721.99\n",
      "mean_3_2017: 500.73\n",
      "mean_4_dow5_2017: 338.52\n",
      "mean_4_dow3_2017: 333.04\n",
      "day_1_2017: 314.28\n",
      "mean_4_dow2_2017: 261.54\n",
      "mean_4_dow6_2017: 230.44\n",
      "mean_4_dow0_2017: 228.54\n",
      "mean_20_dow2_2017: 214.74\n",
      "mean_20_dow5_2017: 205.70\n",
      "mean_20_dow6_2017: 191.71\n",
      "mean_20_dow4_2017: 153.11\n",
      "mean_20_dow3_2017: 138.78\n",
      "mean_4_dow4_2017: 127.08\n",
      "==================================================\n",
      "Step 3\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's l2: 0.314202\tvalid_1's l2: 0.318394\n",
      "mean_14_2017: 23202.72\n",
      "mean_7_2017: 17815.28\n",
      "mean_20_dow2_2017: 9061.33\n",
      "mean_4_dow2_2017: 5321.14\n",
      "promo_2: 2011.50\n",
      "mean_20_dow1_2017: 569.81\n",
      "day_1_2017: 322.63\n",
      "mean_20_dow0_2017: 311.70\n",
      "mean_4_dow6_2017: 279.43\n",
      "mean_4_dow1_2017: 264.49\n",
      "mean_3_2017: 213.72\n",
      "mean_20_dow6_2017: 176.05\n",
      "mean_20_dow3_2017: 172.31\n",
      "mean_20_dow5_2017: 146.65\n",
      "mean_4_dow0_2017: 110.01\n",
      "mean_4_dow5_2017: 108.37\n",
      "mean_20_dow4_2017: 95.79\n",
      "mean_4_dow4_2017: 85.33\n",
      "mean_4_dow3_2017: 57.69\n",
      "==================================================\n",
      "Step 4\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's l2: 0.311546\tvalid_1's l2: 0.310402\n",
      "mean_14_2017: 25263.58\n",
      "mean_7_2017: 17526.44\n",
      "mean_20_dow3_2017: 5045.47\n",
      "mean_4_dow3_2017: 2646.84\n",
      "mean_20_dow4_2017: 2009.17\n",
      "promo_3: 1563.89\n",
      "mean_3_2017: 512.31\n",
      "mean_4_dow6_2017: 354.26\n",
      "mean_4_dow4_2017: 287.18\n",
      "mean_4_dow2_2017: 258.12\n",
      "mean_20_dow2_2017: 240.99\n",
      "mean_20_dow6_2017: 172.47\n",
      "mean_20_dow5_2017: 165.20\n",
      "mean_4_dow5_2017: 158.23\n",
      "mean_20_dow1_2017: 154.33\n",
      "mean_20_dow0_2017: 147.10\n",
      "mean_4_dow1_2017: 135.99\n",
      "day_1_2017: 95.92\n",
      "mean_4_dow0_2017: 82.70\n",
      "==================================================\n",
      "Step 5\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[48]\ttraining's l2: 0.232498\tvalid_1's l2: 0.240412\n",
      "mean_7_2017: 11497.30\n",
      "mean_20_dow4_2017: 8492.75\n",
      "mean_14_2017: 5664.92\n",
      "promo_4: 1447.75\n",
      "mean_4_dow4_2017: 692.71\n",
      "mean_20_dow3_2017: 555.57\n",
      "mean_3_2017: 448.75\n",
      "mean_4_dow3_2017: 426.93\n",
      "day_1_2017: 384.43\n",
      "mean_4_dow5_2017: 347.44\n",
      "mean_20_dow5_2017: 286.54\n",
      "mean_4_dow2_2017: 179.02\n",
      "mean_4_dow6_2017: 161.37\n",
      "mean_20_dow0_2017: 151.81\n",
      "mean_4_dow1_2017: 142.66\n",
      "mean_20_dow1_2017: 130.55\n",
      "mean_4_dow0_2017: 129.24\n",
      "mean_20_dow6_2017: 111.78\n",
      "mean_20_dow2_2017: 84.43\n",
      "==================================================\n",
      "Step 6\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[48]\ttraining's l2: 0.302642\tvalid_1's l2: 0.327647\n",
      "mean_14_2017: 24732.38\n",
      "mean_7_2017: 17385.55\n",
      "mean_20_dow5_2017: 5848.95\n",
      "mean_4_dow5_2017: 1948.93\n",
      "promo_5: 1426.64\n",
      "mean_20_dow6_2017: 1207.59\n",
      "mean_3_2017: 1050.52\n",
      "mean_4_dow6_2017: 646.09\n",
      "mean_20_dow0_2017: 414.91\n",
      "day_1_2017: 326.64\n",
      "mean_4_dow3_2017: 324.35\n",
      "mean_4_dow2_2017: 250.15\n",
      "mean_20_dow4_2017: 213.66\n",
      "mean_4_dow0_2017: 212.40\n",
      "mean_20_dow3_2017: 199.82\n",
      "mean_4_dow1_2017: 167.20\n",
      "mean_20_dow1_2017: 155.05\n",
      "mean_4_dow4_2017: 139.35\n",
      "mean_20_dow2_2017: 113.47\n",
      "==================================================\n",
      "Step 7\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's l2: 0.3218\tvalid_1's l2: 0.341281\n",
      "mean_14_2017: 24313.65\n",
      "mean_7_2017: 12801.30\n",
      "mean_20_dow6_2017: 7845.52\n",
      "mean_20_dow5_2017: 2203.84\n",
      "promo_6: 1461.38\n",
      "mean_4_dow6_2017: 1423.18\n",
      "mean_20_dow0_2017: 735.85\n",
      "mean_4_dow5_2017: 721.42\n",
      "mean_4_dow0_2017: 504.00\n",
      "mean_4_dow2_2017: 403.18\n",
      "mean_4_dow3_2017: 362.73\n",
      "day_1_2017: 309.36\n",
      "mean_20_dow1_2017: 306.03\n",
      "mean_3_2017: 293.43\n",
      "mean_20_dow4_2017: 242.96\n",
      "mean_20_dow3_2017: 206.09\n",
      "mean_4_dow1_2017: 204.37\n",
      "mean_20_dow2_2017: 162.71\n",
      "mean_4_dow4_2017: 106.03\n",
      "==================================================\n",
      "Step 8\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[46]\ttraining's l2: 0.311517\tvalid_1's l2: 0.328588\n",
      "mean_14_2017: 26785.97\n",
      "mean_20_dow0_2017: 16241.40\n",
      "mean_7_2017: 13782.69\n",
      "promo_7: 4933.58\n",
      "mean_20_dow6_2017: 1131.13\n",
      "mean_4_dow0_2017: 733.04\n",
      "day_1_2017: 576.84\n",
      "mean_4_dow5_2017: 552.73\n",
      "mean_4_dow6_2017: 507.30\n",
      "mean_3_2017: 434.04\n",
      "mean_20_dow5_2017: 431.32\n",
      "mean_4_dow2_2017: 341.46\n",
      "mean_20_dow1_2017: 339.50\n",
      "mean_20_dow2_2017: 212.86\n",
      "mean_20_dow3_2017: 207.46\n",
      "mean_4_dow3_2017: 182.63\n",
      "mean_4_dow1_2017: 147.07\n",
      "mean_20_dow4_2017: 121.63\n",
      "mean_4_dow4_2017: 91.44\n",
      "==================================================\n",
      "Step 9\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's l2: 0.326542\tvalid_1's l2: 0.33655\n",
      "mean_7_2017: 19981.37\n",
      "mean_14_2017: 15515.88\n",
      "mean_20_dow1_2017: 8218.87\n",
      "promo_8: 1959.03\n",
      "mean_4_dow1_2017: 959.12\n",
      "mean_4_dow5_2017: 634.30\n",
      "mean_4_dow0_2017: 474.80\n",
      "mean_20_dow0_2017: 408.13\n",
      "mean_20_dow2_2017: 383.57\n",
      "mean_4_dow2_2017: 226.01\n",
      "mean_20_dow4_2017: 218.46\n",
      "mean_4_dow6_2017: 217.23\n",
      "mean_4_dow3_2017: 195.09\n",
      "mean_3_2017: 183.96\n",
      "mean_20_dow5_2017: 158.50\n",
      "mean_20_dow6_2017: 111.43\n",
      "mean_20_dow3_2017: 93.25\n",
      "day_1_2017: 91.10\n",
      "mean_4_dow4_2017: 62.08\n",
      "==================================================\n",
      "Step 10\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[36]\ttraining's l2: 0.329246\tvalid_1's l2: 0.360498\n",
      "mean_20_dow2_2017: 17381.36\n",
      "mean_14_2017: 14183.66\n",
      "mean_7_2017: 13800.47\n",
      "mean_4_dow2_2017: 6064.26\n",
      "promo_9: 2659.72\n",
      "mean_20_dow1_2017: 1113.84\n",
      "mean_20_dow0_2017: 651.43\n",
      "mean_4_dow5_2017: 503.76\n",
      "mean_4_dow6_2017: 376.13\n",
      "mean_20_dow6_2017: 222.34\n",
      "mean_20_dow4_2017: 187.29\n",
      "mean_20_dow3_2017: 174.50\n",
      "day_1_2017: 172.75\n",
      "mean_4_dow0_2017: 171.28\n",
      "mean_3_2017: 169.31\n",
      "mean_4_dow3_2017: 168.05\n",
      "mean_20_dow5_2017: 148.51\n",
      "mean_4_dow1_2017: 136.68\n",
      "mean_4_dow4_2017: 86.82\n",
      "==================================================\n",
      "Step 11\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's l2: 0.332412\tvalid_1's l2: 0.333606\n",
      "mean_14_2017: 21263.47\n",
      "mean_7_2017: 10802.94\n",
      "mean_20_dow3_2017: 9680.48\n",
      "mean_4_dow3_2017: 3926.73\n",
      "mean_20_dow4_2017: 2565.64\n",
      "promo_10: 1934.89\n",
      "mean_4_dow4_2017: 598.71\n",
      "mean_4_dow2_2017: 352.19\n",
      "mean_20_dow5_2017: 297.26\n",
      "mean_4_dow6_2017: 260.99\n",
      "mean_20_dow6_2017: 248.84\n",
      "mean_20_dow1_2017: 241.72\n",
      "mean_20_dow2_2017: 220.11\n",
      "mean_4_dow1_2017: 201.03\n",
      "mean_4_dow5_2017: 174.77\n",
      "mean_20_dow0_2017: 164.03\n",
      "mean_3_2017: 88.76\n",
      "day_1_2017: 70.17\n",
      "mean_4_dow0_2017: 51.22\n",
      "==================================================\n",
      "Step 12\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's l2: 0.247391\tvalid_1's l2: 0.240933\n",
      "mean_20_dow4_2017: 14110.55\n",
      "mean_14_2017: 7244.62\n",
      "promo_11: 1824.44\n",
      "mean_7_2017: 1192.41\n",
      "mean_4_dow3_2017: 1077.87\n",
      "mean_4_dow4_2017: 955.14\n",
      "mean_4_dow5_2017: 560.58\n",
      "mean_4_dow6_2017: 425.22\n",
      "mean_20_dow3_2017: 383.96\n",
      "mean_3_2017: 281.36\n",
      "mean_20_dow5_2017: 241.45\n",
      "mean_4_dow0_2017: 202.55\n",
      "mean_4_dow1_2017: 172.93\n",
      "mean_20_dow6_2017: 133.82\n",
      "mean_20_dow0_2017: 104.79\n",
      "mean_4_dow2_2017: 88.92\n",
      "mean_20_dow1_2017: 81.13\n",
      "mean_20_dow2_2017: 69.16\n",
      "day_1_2017: 42.45\n",
      "==================================================\n",
      "Step 13\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's l2: 0.327274\tvalid_1's l2: 0.340981\n",
      "mean_14_2017: 21951.21\n",
      "mean_7_2017: 15097.79\n",
      "mean_20_dow5_2017: 7396.12\n",
      "mean_4_dow5_2017: 2183.31\n",
      "promo_12: 1921.69\n",
      "mean_20_dow6_2017: 1679.24\n",
      "mean_4_dow6_2017: 1380.27\n",
      "mean_4_dow3_2017: 327.84\n",
      "mean_4_dow1_2017: 260.95\n",
      "mean_20_dow2_2017: 230.90\n",
      "mean_3_2017: 228.06\n",
      "mean_20_dow0_2017: 219.30\n",
      "mean_4_dow4_2017: 188.98\n",
      "mean_20_dow1_2017: 183.41\n",
      "mean_20_dow4_2017: 173.15\n",
      "mean_4_dow0_2017: 165.61\n",
      "day_1_2017: 126.48\n",
      "mean_4_dow2_2017: 122.17\n",
      "mean_20_dow3_2017: 94.80\n",
      "==================================================\n",
      "Step 14\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's l2: 0.338146\tvalid_1's l2: 0.382329\n",
      "mean_14_2017: 20104.40\n",
      "mean_20_dow6_2017: 15740.98\n",
      "mean_7_2017: 6077.04\n",
      "promo_13: 1947.17\n",
      "mean_20_dow5_2017: 1831.11\n",
      "mean_4_dow0_2017: 1290.81\n",
      "mean_4_dow6_2017: 1029.22\n",
      "mean_4_dow5_2017: 996.19\n",
      "mean_4_dow2_2017: 630.49\n",
      "mean_20_dow0_2017: 480.64\n",
      "mean_20_dow2_2017: 424.04\n",
      "mean_20_dow1_2017: 385.61\n",
      "mean_3_2017: 363.19\n",
      "day_1_2017: 337.11\n",
      "mean_4_dow1_2017: 251.82\n",
      "mean_20_dow3_2017: 166.95\n",
      "mean_20_dow4_2017: 166.51\n",
      "mean_4_dow3_2017: 107.51\n",
      "mean_4_dow4_2017: 67.90\n",
      "==================================================\n",
      "Step 15\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[40]\ttraining's l2: 0.322916\tvalid_1's l2: 0.341895\n",
      "mean_20_dow0_2017: 25321.63\n",
      "mean_14_2017: 14440.68\n",
      "mean_7_2017: 8943.95\n",
      "promo_14: 6236.59\n",
      "mean_4_dow0_2017: 5051.67\n",
      "mean_20_dow6_2017: 1506.58\n",
      "mean_20_dow5_2017: 810.86\n",
      "mean_4_dow5_2017: 768.49\n",
      "mean_20_dow1_2017: 335.61\n",
      "day_1_2017: 325.06\n",
      "mean_4_dow2_2017: 304.95\n",
      "mean_4_dow6_2017: 292.53\n",
      "mean_3_2017: 272.03\n",
      "mean_20_dow3_2017: 213.09\n",
      "mean_4_dow1_2017: 208.66\n",
      "mean_20_dow4_2017: 187.36\n",
      "mean_20_dow2_2017: 182.33\n",
      "mean_4_dow3_2017: 134.70\n",
      "mean_4_dow4_2017: 121.62\n",
      "==================================================\n",
      "Step 16\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[46]\ttraining's l2: 0.326836\tvalid_1's l2: 0.369949\n",
      "mean_14_2017: 20138.13\n",
      "mean_20_dow1_2017: 13693.20\n",
      "mean_7_2017: 8868.14\n",
      "promo_15: 2112.10\n",
      "mean_4_dow1_2017: 1420.60\n",
      "mean_4_dow5_2017: 725.04\n",
      "mean_20_dow6_2017: 635.44\n",
      "mean_20_dow0_2017: 474.14\n",
      "mean_20_dow2_2017: 400.70\n",
      "mean_4_dow3_2017: 287.42\n",
      "mean_4_dow6_2017: 283.90\n",
      "mean_4_dow2_2017: 280.31\n",
      "mean_4_dow0_2017: 273.50\n",
      "mean_20_dow5_2017: 237.35\n",
      "mean_20_dow4_2017: 201.23\n",
      "mean_20_dow3_2017: 167.29\n",
      "mean_4_dow4_2017: 165.06\n",
      "day_1_2017: 160.30\n",
      "mean_3_2017: 121.47\n",
      "Validation mse: 0.320128202637\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#------------------------------------------------------------------------------------------#\n",
    "logger.info('Training and predicting models...')\n",
    "\n",
    "params = {\n",
    "    'num_leaves': 31,\n",
    "    'objective': 'regression',\n",
    "    'min_data_in_leaf': 300,\n",
    "    'learning_rate': 0.1,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 2,\n",
    "    'metric': 'l2',\n",
    "    'num_threads': 4\n",
    "}\n",
    "\n",
    "MAX_ROUNDS = 500\n",
    "val_pred = []\n",
    "test_pred = []\n",
    "cate_vars = []\n",
    "\n",
    "features_all = X_train_allF.columns.tolist()\n",
    "\n",
    "   \n",
    "for i in range(16):\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Step %d\" % (i+1))\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    features_t = features_all.copy()\n",
    "    \n",
    "    for j in range(16):\n",
    "        if j != i:\n",
    "            features_t.remove(\"promo_{}\".format(j))\n",
    "    \n",
    "\n",
    "    X_train = X_train_allF[features_t]\n",
    "    X_val = X_val_allF[features_t]\n",
    "    \n",
    "    dtrain = lgb.Dataset(\n",
    "        X_train, label=y_train[:, i],\n",
    "        categorical_feature=cate_vars,\n",
    "        weight=pd.concat([items[\"perishable\"]] * 6) * 0.25 + 1\n",
    "    )\n",
    "    dval = lgb.Dataset(\n",
    "        X_val, label=y_val[:, i], reference=dtrain,\n",
    "        weight=items[\"perishable\"] * 0.25 + 1,\n",
    "        categorical_feature=cate_vars)\n",
    "    bst = lgb.train(\n",
    "        params, dtrain, num_boost_round=MAX_ROUNDS,\n",
    "        valid_sets=[dtrain, dval], early_stopping_rounds=50, verbose_eval=100\n",
    "    )\n",
    "    print(\"\\n\".join((\"%s: %.2f\" % x) for x in sorted(\n",
    "        zip(X_train.columns, bst.feature_importance(\"gain\")),\n",
    "        key=lambda x: x[1], reverse=True\n",
    "    )))\n",
    "    val_pred.append(bst.predict(\n",
    "        X_val, num_iteration=bst.best_iteration or MAX_ROUNDS))\n",
    "    test_pred.append(bst.predict(\n",
    "        X_test, num_iteration=bst.best_iteration or MAX_ROUNDS))\n",
    "\n",
    "print(\"Validation mse:\", mean_squared_error(\n",
    "    y_val, np.array(val_pred).transpose()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-01-02 11:01:16,845 __main__ 6 [INFO][<module>] validate accuracy ... \n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/T006_lgb_val.p'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-0fdfe748a6b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mtest_e\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/T006_lgb_val.p'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m#------------------------------------------------------------------------------------------#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_pickle\u001b[0;34m(self, path, compression)\u001b[0m\n\u001b[1;32m   1376\u001b[0m         \"\"\"\n\u001b[1;32m   1377\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpickle\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1378\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mto_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1380\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_clipboard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexcel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mto_pickle\u001b[0;34m(obj, path, compression)\u001b[0m\n\u001b[1;32m     25\u001b[0m     f, fh = _get_handle(path, 'wb',\n\u001b[1;32m     26\u001b[0m                         \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minferred_compression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                         is_text=False)\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mpkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHIGHEST_PROTOCOL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0;31m# Python 3 and binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/T006_lgb_val.p'"
     ]
    }
   ],
   "source": [
    "\n",
    "del X_train, y_train\n",
    "#------------------------------------------------------------------------------------------#\n",
    "# Validate \n",
    "#### Need to use expm1 when y is log1p\n",
    "logger.info('validate accuracy ...')\n",
    "\n",
    "valid = pd.DataFrame(\n",
    "    np.expm1(y_val), index=df_2017.index,\n",
    "    columns=pd.date_range(\"2017-07-26\", periods=16)\n",
    ").stack().to_frame(\"unit_sales\")\n",
    "\n",
    "pred = pd.DataFrame(\n",
    "    np.expm1(np.array(val_pred).transpose()), index=df_2017.index,\n",
    "    columns=pd.date_range(\"2017-07-26\", periods=16)\n",
    ").stack().to_frame(\"pred_sales\")\n",
    "\n",
    "valid = valid.reset_index()\n",
    "pred = pred.reset_index()\n",
    "\n",
    "test_e = pd.merge(valid, pred, on=['item_nbr','store_nbr', 'level_2'])\n",
    "#items = items.reset_index()\n",
    "\n",
    "#test_e = pd.merge(valid_m, items, on='item_nbr',how='inner')\n",
    "test_e[\"date\"] = test_e.level_2\n",
    "\n",
    "#del valid, pred\n",
    "#del X_val, y_val\n",
    "\n",
    "\n",
    "test_e.to_pickle('./data/T006_lgb_val.p')\n",
    "\n",
    "#------------------------------------------------------------------------------------------#\n",
    "# Submit\n",
    "logger.info('Making submission...')\n",
    "\n",
    "y_test = np.array(test_pred).transpose()\n",
    "df_preds = pd.DataFrame(\n",
    "    y_test, index=df_2017.index,\n",
    "    columns=pd.date_range(\"2017-08-16\", periods=16)\n",
    ").stack().to_frame(\"unit_sales\")\n",
    "df_preds.index.set_names([\"store_nbr\", \"item_nbr\", \"date\"], inplace=True)\n",
    "\n",
    "submission = df_test[[\"id\"]].join(df_preds, how=\"left\").fillna(0)\n",
    "submission[\"unit_sales\"] = np.clip(np.expm1(submission[\"unit_sales\"]), 0, 1000)\n",
    "submission.to_csv('../submit/T006_lgb_moreWK.csv', float_format='%.4f', index=None)\n",
    "\n",
    "####### PZ, Check overral result\n",
    "print(\"SUM =\",  submission.unit_sales.sum())\n",
    "print(\"MEAN =\",  submission.unit_sales.mean())\n",
    "\n",
    "print(mean_squared_error(y_val, np.array(val_pred).transpose()))\n",
    "print(submission.unit_sales.sum())\n",
    "print(submission.unit_sales.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
